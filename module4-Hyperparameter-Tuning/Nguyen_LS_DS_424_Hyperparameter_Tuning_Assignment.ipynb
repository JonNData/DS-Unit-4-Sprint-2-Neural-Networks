{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nguyen_LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonNData/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/module4-Hyperparameter-Tuning/Nguyen_LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Ryp-TVm4njD"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
        "\n",
        "## Your Mission, should you choose to accept it...\n",
        "\n",
        "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: [Available Here](https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv)\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Load the data\n",
        "- Clean the data if necessary (it will be)\n",
        "- Create and fit a baseline Keras MLP model to the data.\n",
        "- Hyperparameter tune (at least) the following parameters:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (if applicable to optimizer)\n",
        " - momentum (if applicable to optimizer)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
        " \n",
        " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NNJ-tOBs4jM1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "c6e1789d-1582-4994-f84b-94fd2407eae7"
      },
      "source": [
        "##### Your Code Here #####\n",
        "import pandas as pd\n",
        "url = 'https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv'\n",
        "df = pd.read_csv(url)\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7038</th>\n",
              "      <td>6840-RESVB</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>24</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>84.80</td>\n",
              "      <td>1990.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7039</th>\n",
              "      <td>2234-XADUH</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>72</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Credit card (automatic)</td>\n",
              "      <td>103.20</td>\n",
              "      <td>7362.9</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7040</th>\n",
              "      <td>4801-JZAZL</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>11</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.60</td>\n",
              "      <td>346.45</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7041</th>\n",
              "      <td>8361-LTMKD</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>74.40</td>\n",
              "      <td>306.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7042</th>\n",
              "      <td>3186-AJIEK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>66</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Two year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>105.65</td>\n",
              "      <td>6844.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7043 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      customerID  gender  SeniorCitizen  ... MonthlyCharges TotalCharges  Churn\n",
              "0     7590-VHVEG  Female              0  ...          29.85        29.85     No\n",
              "1     5575-GNVDE    Male              0  ...          56.95       1889.5     No\n",
              "2     3668-QPYBK    Male              0  ...          53.85       108.15    Yes\n",
              "3     7795-CFOCW    Male              0  ...          42.30      1840.75     No\n",
              "4     9237-HQITU  Female              0  ...          70.70       151.65    Yes\n",
              "...          ...     ...            ...  ...            ...          ...    ...\n",
              "7038  6840-RESVB    Male              0  ...          84.80       1990.5     No\n",
              "7039  2234-XADUH  Female              0  ...         103.20       7362.9     No\n",
              "7040  4801-JZAZL  Female              0  ...          29.60       346.45     No\n",
              "7041  8361-LTMKD    Male              1  ...          74.40        306.6    Yes\n",
              "7042  3186-AJIEK    Male              0  ...         105.65       6844.5     No\n",
              "\n",
              "[7043 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJCaS71N9iiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X features matrix and y target vector\n",
        "features = list(df1)[:-1]\n",
        "target = list(df1)[-1]\n",
        "X = df1[features]\n",
        "y = df1[target].apply(lambda x: 1 if x == 'Yes' else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1QppFZtB5wU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "80fef6b6-f15c-4ede-ba5a-e2682f9dfcaf"
      },
      "source": [
        "# Target encode all categories\n",
        "!pip install category_encoders\n",
        "from category_encoders.target_encoder import TargetEncoder\n",
        "\n",
        "encoder = TargetEncoder()\n",
        "X_encoded = encoder.fit_transform(X, y)\n",
        "encoder.get_feature_names"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method TargetEncoder.get_feature_names of TargetEncoder(cols=['customerID', 'gender', 'Partner', 'Dependents',\n",
              "                    'PhoneService', 'MultipleLines', 'InternetService',\n",
              "                    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
              "                    'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
              "                    'PaperlessBilling', 'PaymentMethod', 'TotalCharges'],\n",
              "              drop_invariant=False, handle_missing='value',\n",
              "              handle_unknown='value', min_samples_leaf=1, return_df=True,\n",
              "              smoothing=1.0, verbose=0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNHsr_CWv8kf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0bd30953-46eb-43b8-f723-61143d0f808a"
      },
      "source": [
        "# Standard scale\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_norm = scaler.fit_transform(X_encoded)\n",
        "X_norm"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        ,  1.00955867, -0.43991649, ...,  1.39974289,\n",
              "        -1.16032292, -0.15193369],\n",
              "       [-1.        , -0.99053183, -0.43991649, ..., -0.55473949,\n",
              "        -0.25962894, -0.15193369],\n",
              "       [-1.        , -0.99053183, -0.43991649, ..., -0.55473949,\n",
              "        -0.36266036, -0.15193369],\n",
              "       ...,\n",
              "       [-1.        ,  1.00955867, -0.43991649, ...,  1.39974289,\n",
              "        -1.1686319 , -0.15193369],\n",
              "       [-1.        , -0.99053183,  2.27315869, ..., -0.55473949,\n",
              "         0.32033821, -0.15193369],\n",
              "       [-1.        , -0.99053183, -0.43991649, ..., -0.73368684,\n",
              "         1.35896134, -0.15193369]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq7W-AjfMArm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d97c66c7-4476-425f-c69a-fa5ea3fcb534"
      },
      "source": [
        "X_norm.shape, X_norm[0].shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7043, 20), (20,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EdFJss9MEX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "2c8d4ab5-1089-4412-d0f5-93ea38b24ca5"
      },
      "source": [
        "# Baseline keras ML model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=X_norm[0].shape))\n",
        "model.add(Dense(10))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "baseline = model.fit(X_norm, y, validation_split=0.2, epochs=20)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.6021 - val_loss: 0.4797 - val_accuracy: 0.7715\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7922 - val_loss: 0.4099 - val_accuracy: 0.8006\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4004 - accuracy: 0.8129 - val_loss: 0.3999 - val_accuracy: 0.8055\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8174 - val_loss: 0.3983 - val_accuracy: 0.8105\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8195 - val_loss: 0.3974 - val_accuracy: 0.8155\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8191 - val_loss: 0.3985 - val_accuracy: 0.8176\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8207 - val_loss: 0.3969 - val_accuracy: 0.8176\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8211 - val_loss: 0.3966 - val_accuracy: 0.8133\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8204 - val_loss: 0.3965 - val_accuracy: 0.8162\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8234 - val_loss: 0.3969 - val_accuracy: 0.8112\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8198 - val_loss: 0.3969 - val_accuracy: 0.8148\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8191 - val_loss: 0.3962 - val_accuracy: 0.8148\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8198 - val_loss: 0.3961 - val_accuracy: 0.8133\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8211 - val_loss: 0.3961 - val_accuracy: 0.8148\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8193 - val_loss: 0.3963 - val_accuracy: 0.8112\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8195 - val_loss: 0.3978 - val_accuracy: 0.8126\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8197 - val_loss: 0.3967 - val_accuracy: 0.8126\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8209 - val_loss: 0.3977 - val_accuracy: 0.8133\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8209 - val_loss: 0.3958 - val_accuracy: 0.8148\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8209 - val_loss: 0.3965 - val_accuracy: 0.8141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Dx6iu1RKWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "e84bb27c-f934-46fe-a796-a060186d271d"
      },
      "source": [
        "# Baseline!\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "plt.plot(baseline.history['accuracy'])\n",
        "plt.plot(baseline.history['val_accuracy'])\n",
        "plt.title('Baseline accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(baseline.history['loss'])\n",
        "plt.plot(baseline.history['val_loss'])\n",
        "plt.title('Baseline loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAK_wi9IT89Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4db4fe77-8a78-4780-9279-ea7577f72801"
      },
      "source": [
        "X_norm"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        ,  1.00955867, -0.43991649, ...,  1.39974289,\n",
              "        -1.16032292, -0.15193369],\n",
              "       [-1.        , -0.99053183, -0.43991649, ..., -0.55473949,\n",
              "        -0.25962894, -0.15193369],\n",
              "       [-1.        , -0.99053183, -0.43991649, ..., -0.55473949,\n",
              "        -0.36266036, -0.15193369],\n",
              "       ...,\n",
              "       [-1.        ,  1.00955867, -0.43991649, ...,  1.39974289,\n",
              "        -1.1686319 , -0.15193369],\n",
              "       [-1.        , -0.99053183,  2.27315869, ..., -0.55473949,\n",
              "         0.32033821, -0.15193369],\n",
              "       [-1.        , -0.99053183, -0.43991649, ..., -0.73368684,\n",
              "         1.35896134, -0.15193369]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfu_1Obk_q_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper param tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# We use an api wrapper to that we can work with scikit_learn's gridsearchCV\n",
        "# KerasClassifier's build_fn param needs a function of the model builder to \n",
        "# iterate over. So let's make that function\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=X_norm[0].shape))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# now instantiate KerasClassifier with your function, first time calling model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QPcMsAdUNof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ca69103-be0e-4299-d478-9f4f2a401e62"
      },
      "source": [
        "# now lets grid search some params!\n",
        "param_grid = {'batch_size': [32,64,128,256,512],\n",
        "              'epochs': [20]}\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-3)\n",
        "grid_result = grid.fit(X_norm, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.6647\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7895\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8033\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8099\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4060 - accuracy: 0.8104\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4031 - accuracy: 0.8143\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.8140\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8120\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8135\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.8154\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8152\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8152\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8147\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8170\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3933 - accuracy: 0.8174\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8188\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8174\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8168\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8166\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.8172\n",
            "45/45 [==============================] - 0s 984us/step - loss: 0.3735 - accuracy: 0.8247\n",
            "Epoch 1/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6239\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7618\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7874\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7980\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8080\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8110\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8131\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8149\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8159\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8165\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8179\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8166\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8191\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8197\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8204\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8200\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8204\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8204\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8220\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8225\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8112\n",
            "Epoch 1/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7261\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.7868\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4116 - accuracy: 0.7982\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8046\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.8099\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8108\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8143\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8161\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8166\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8195\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8213\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8198\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8227\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8230\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8234\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8175\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8239\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3870 - accuracy: 0.8229\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8253\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8234\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8133\n",
            "Epoch 1/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.6882\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7746\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.7947\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8004\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.8106\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8128\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8154\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8135\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8169\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8204\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8190\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8201\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8215\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3848 - accuracy: 0.8185\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8206\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8201\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8220\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8217\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8202\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8217\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8189\n",
            "Epoch 1/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7209\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7831\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8016\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8080\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8122\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8153\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8177\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8192\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8193\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8197\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8206\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8193\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8204\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8213\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8240\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8227\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8236\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8232\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8240\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8243\n",
            "44/44 [==============================] - 0s 953us/step - loss: 0.4098 - accuracy: 0.8047\n",
            "Epoch 1/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7575\n",
            "Epoch 2/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7845\n",
            "Epoch 3/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7959\n",
            "Epoch 4/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8009\n",
            "Epoch 5/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8037\n",
            "Epoch 6/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8049\n",
            "Epoch 7/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8088\n",
            "Epoch 8/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.8119\n",
            "Epoch 9/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8106\n",
            "Epoch 10/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4103 - accuracy: 0.8106\n",
            "Epoch 11/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8117\n",
            "Epoch 12/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8129\n",
            "Epoch 13/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.8140\n",
            "Epoch 14/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.8138\n",
            "Epoch 15/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8154\n",
            "Epoch 16/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.8152\n",
            "Epoch 17/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8149\n",
            "Epoch 18/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8159\n",
            "Epoch 19/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8172\n",
            "Epoch 20/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8165\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8119\n",
            "Epoch 1/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.7013\n",
            "Epoch 2/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7817\n",
            "Epoch 3/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7994\n",
            "Epoch 4/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8039\n",
            "Epoch 5/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8067\n",
            "Epoch 6/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8088\n",
            "Epoch 7/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8108\n",
            "Epoch 8/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8145\n",
            "Epoch 9/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4021 - accuracy: 0.8135\n",
            "Epoch 10/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8151\n",
            "Epoch 11/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8149\n",
            "Epoch 12/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8163\n",
            "Epoch 13/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8151\n",
            "Epoch 14/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8179\n",
            "Epoch 15/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8172\n",
            "Epoch 16/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.8179\n",
            "Epoch 17/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8186\n",
            "Epoch 18/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8184\n",
            "Epoch 19/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8186\n",
            "Epoch 20/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8191\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8155\n",
            "Epoch 1/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.7651 - accuracy: 0.5094\n",
            "Epoch 2/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.7368\n",
            "Epoch 3/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7822\n",
            "Epoch 4/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.7920\n",
            "Epoch 5/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7991\n",
            "Epoch 6/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.8049\n",
            "Epoch 7/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8090\n",
            "Epoch 8/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8140\n",
            "Epoch 9/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8190\n",
            "Epoch 10/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.8191\n",
            "Epoch 11/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8195\n",
            "Epoch 12/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8211\n",
            "Epoch 13/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8206\n",
            "Epoch 14/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8200\n",
            "Epoch 15/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8202\n",
            "Epoch 16/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8202\n",
            "Epoch 17/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8200\n",
            "Epoch 18/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8207\n",
            "Epoch 19/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8227\n",
            "Epoch 20/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8223\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.8055\n",
            "Epoch 1/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 1.0812 - accuracy: 0.3246\n",
            "Epoch 2/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.5713\n",
            "Epoch 3/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.7276\n",
            "Epoch 4/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7759\n",
            "Epoch 5/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7945\n",
            "Epoch 6/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8034\n",
            "Epoch 7/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8071\n",
            "Epoch 8/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8101\n",
            "Epoch 9/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4021 - accuracy: 0.8133\n",
            "Epoch 10/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8151\n",
            "Epoch 11/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8140\n",
            "Epoch 12/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8135\n",
            "Epoch 13/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8153\n",
            "Epoch 14/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8144\n",
            "Epoch 15/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8160\n",
            "Epoch 16/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3908 - accuracy: 0.8165\n",
            "Epoch 17/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8177\n",
            "Epoch 18/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4035 - accuracy: 0.8174\n",
            "Epoch 19/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8197\n",
            "Epoch 20/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8181\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8189\n",
            "Epoch 1/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.6222\n",
            "Epoch 2/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7693\n",
            "Epoch 3/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7881\n",
            "Epoch 4/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.7941\n",
            "Epoch 5/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.7993\n",
            "Epoch 6/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8037\n",
            "Epoch 7/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8091\n",
            "Epoch 8/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8126\n",
            "Epoch 9/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8147\n",
            "Epoch 10/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8149\n",
            "Epoch 11/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8165\n",
            "Epoch 12/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8192\n",
            "Epoch 13/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8190\n",
            "Epoch 14/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8209\n",
            "Epoch 15/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8209\n",
            "Epoch 16/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8231\n",
            "Epoch 17/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3870 - accuracy: 0.8227\n",
            "Epoch 18/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8236\n",
            "Epoch 19/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8231\n",
            "Epoch 20/20\n",
            "89/89 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8218\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.8104\n",
            "Epoch 1/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.9844 - accuracy: 0.3475\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.5362\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7158\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7600\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7780\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7898\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7978\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.7993\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.8040\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8053\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4049 - accuracy: 0.8085\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8097\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8099\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8133\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8126\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8143\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8154\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8149\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8152\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8166\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8148\n",
            "Epoch 1/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.6416\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7066\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7467\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7765\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7943\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7964\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8021\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8056\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8087\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4207 - accuracy: 0.8085\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8099\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8108\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8120\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.8129\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8129\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8119\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8115\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8120\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8115\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8110\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8155\n",
            "Epoch 1/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6192 - accuracy: 0.6438\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7506\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7803\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7961\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8003\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8053\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8076\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8097\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8099\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8119\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8117\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8120\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.8140\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8140\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8143\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.8147\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8133\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.8152\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.8136\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8152\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8141\n",
            "Epoch 1/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.8780 - accuracy: 0.4827\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6158\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5380 - accuracy: 0.7313\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7642\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7778\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7814\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7899\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.7961\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.7965\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8011\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8021\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8044\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8069\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8078\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8078\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4029 - accuracy: 0.8099\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8110\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8137\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8126\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3952 - accuracy: 0.8138\n",
            "11/11 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8146\n",
            "Epoch 1/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6270\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7102\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7604\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7782\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.7878\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.7933\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.7984\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.7996\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.8030\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.8053\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8075\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8083\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.8078\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.8101\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.8105\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8115\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8147\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8151\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8169\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8165\n",
            "11/11 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8104\n",
            "Epoch 1/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5625\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6295 - accuracy: 0.6771\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7315\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7460\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7535\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7634\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7696\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7710\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7742\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7758\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7792\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7845\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.7891\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7920\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7900\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7941\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.7909\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.7906\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4137 - accuracy: 0.7938\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7952\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7935\n",
            "Epoch 1/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.8388 - accuracy: 0.4095\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5550\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6135 - accuracy: 0.6427\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.6851\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7126\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5528 - accuracy: 0.7242\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7371\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7472\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7599\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7721\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7790\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7836\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7893\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7961\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7966\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8009\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.8007\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8035\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8042\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8040\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.7949\n",
            "Epoch 1/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6839\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7165\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7348\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7487\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7570\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7691\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7758\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7804\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7849\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7881\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7907\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7913\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7929\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7945\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.7959\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.7987\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8000\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8003\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8016\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8042\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7991\n",
            "Epoch 1/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7198\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7200\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7287\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7336\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.7400\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.7437\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7491\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7528\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7583\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7622\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7672\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7709\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.7728\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7766\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7810\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7830\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7863\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7908\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7899\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7947\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.8040\n",
            "Epoch 1/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.5870\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6864\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7288\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7521\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7606\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7689\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7755\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7785\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7815\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7860\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7874\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7892\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7890\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7927\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7940\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7959\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.7991\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7991\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8000\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8014\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7905\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6443\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.6952\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7226\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7405\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7572\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7654\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7714\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7756\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7780\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7826\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7925\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7927\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7941\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7961\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7980\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7993\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7985\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7973\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.7970\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6530\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6747\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.6908\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7018\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7118\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7196\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.7283\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7311\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7371\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7433\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7472\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7547\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7634\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7657\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7689\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7694\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7723\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7762\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7801\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7819\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7793\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7311\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.7311\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.7302\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7304\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7316\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7368\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7410\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7490\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7536\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7600\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7666\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7723\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7737\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7771\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7780\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7797\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7826\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7838\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7843\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7854\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7835\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8857 - accuracy: 0.3244\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.8118 - accuracy: 0.3663\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.4225\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5157\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6124\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.6141 - accuracy: 0.6733\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5964 - accuracy: 0.7072\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.7239\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5315 - accuracy: 0.7315\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7418\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7484\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7524\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7576\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7638\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7673\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7720\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7746\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7760\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7771\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.7796\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7706\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.1384 - accuracy: 0.3295\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 1.0542 - accuracy: 0.3626\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.9139 - accuracy: 0.4137\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.8329 - accuracy: 0.4603\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.5285\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.6005\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6600\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.6949\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7237\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7425\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7537\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7626\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7670\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7741\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7776\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7821\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7858\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7892\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7906\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7917\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7791\n",
            "Epoch 1/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6104\n",
            "Epoch 2/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7839\n",
            "Epoch 3/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8066\n",
            "Epoch 4/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8105\n",
            "Epoch 5/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8154\n",
            "Epoch 6/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8180\n",
            "Epoch 7/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8180\n",
            "Epoch 8/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8195\n",
            "Epoch 9/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8205\n",
            "Epoch 10/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3922 - accuracy: 0.8227\n",
            "Epoch 11/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8201\n",
            "Epoch 12/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8220\n",
            "Epoch 13/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8221\n",
            "Epoch 14/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8221\n",
            "Epoch 15/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.8221\n",
            "Epoch 16/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8208\n",
            "Epoch 17/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8224\n",
            "Epoch 18/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8222\n",
            "Epoch 19/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8207\n",
            "Epoch 20/20\n",
            "221/221 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8227\n",
            "Best: 0.8145668745040894 using {'batch_size': 32, 'epochs': 20}\n",
            "Means: 0.8145668745040894, Stdev: 0.0068073425468530005 with: {'batch_size': 32, 'epochs': 20}\n",
            "Means: 0.8124384999275207, Stdev: 0.00453968585967138 with: {'batch_size': 64, 'epochs': 20}\n",
            "Means: 0.8138573408126831, Stdev: 0.0018015708046995513 with: {'batch_size': 128, 'epochs': 20}\n",
            "Means: 0.7963938117027283, Stdev: 0.004708315645846271 with: {'batch_size': 256, 'epochs': 20}\n",
            "Means: 0.7819091081619263, Stdev: 0.008644599138839219 with: {'batch_size': 512, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugj5hVUaiVOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "56c52830-a24a-455a-e689-0b2ad558886c"
      },
      "source": [
        "# To add learning rate as a hyperparam you need to specify it in the create_model\n",
        "# It's part of an optimizer so we have to impor that as well\n",
        "\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "\n",
        "def create_model(learning_rate=0.1):\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=X_norm[0].shape))\n",
        "  model.add(Dense(23, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  optimizer = Nadam(learning_rate=learning_rate)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "\n",
        "param_grid = {'learning_rate': [.001, .01, .1, .2, .3, .5],\n",
        "              'epochs': [30]}\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-3)\n",
        "grid_result = grid.fit(X_norm, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8166968345642089 using {'epochs': 30, 'learning_rate': 0.001}\n",
            "Means: 0.8166968345642089, Stdev: 0.003060274547568726 with: {'epochs': 30, 'learning_rate': 0.001}\n",
            "Means: 0.809882402420044, Stdev: 0.008598462388453463 with: {'epochs': 30, 'learning_rate': 0.01}\n",
            "Means: 0.8104520916938782, Stdev: 0.007367356782833735 with: {'epochs': 30, 'learning_rate': 0.1}\n",
            "Means: 0.7616063952445984, Stdev: 0.027210225706029604 with: {'epochs': 30, 'learning_rate': 0.2}\n",
            "Means: 0.7349126458168029, Stdev: 0.004718131278199194 with: {'epochs': 30, 'learning_rate': 0.3}\n",
            "Means: 0.6381063997745514, Stdev: 0.18990875613724623 with: {'epochs': 30, 'learning_rate': 0.5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GVmJaoRIeKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1a60b73d-c76a-4169-eb9d-3fa461a0f51e"
      },
      "source": [
        "# Further tweaking \n",
        "def create_model(optimizer='adam', init='uniform' ):\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=X_norm[0].shape))\n",
        "  model.add(Dense(23, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  #optimizer = Nadam(learning_rate=learning_rate)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "param_grid = {#'learning_rate': [.001, 0.0005],\n",
        "              'epochs': [50],\n",
        "              'batch_size': [32],\n",
        "              'optimizer': ['rmsprop', 'adam', 'nadam'],\n",
        "              'init': ['glorot_uniform', 'normal', 'uniform']\n",
        "              }\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-3)\n",
        "grid_result = grid.fit(X_norm, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8176910519599915 using {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.8125795364379883, Stdev: 0.0035816012990457172 with: {'batch_size': 32, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.8121535062789917, Stdev: 0.0035172800597427843 with: {'batch_size': 32, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "Means: 0.8165560126304626, Stdev: 0.002677631645659132 with: {'batch_size': 32, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'nadam'}\n",
            "Means: 0.8164129495620728, Stdev: 0.004740089485977629 with: {'batch_size': 32, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
            "Means: 0.8155614852905273, Stdev: 0.004295189000996745 with: {'batch_size': 32, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
            "Means: 0.8135738492012023, Stdev: 0.004566301651920762 with: {'batch_size': 32, 'epochs': 50, 'init': 'normal', 'optimizer': 'nadam'}\n",
            "Means: 0.8125781178474426, Stdev: 0.0069006195274146365 with: {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
            "Means: 0.8176910519599915, Stdev: 0.0057812134656918205 with: {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "Means: 0.8154197454452514, Stdev: 0.004251319407525747 with: {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'nadam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-HuTpPkqBoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7317e739-c398-479c-85fe-6807e87ea76a"
      },
      "source": [
        "# Now let's try and run what we learned\n",
        "\n",
        "def create_model(learning_rate=0.001, init='uniform'):\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=X_norm[0].shape))\n",
        "  model.add(Dense(10, kernel_initializer=init,activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer=init,activation='sigmoid'))\n",
        "\n",
        "  optimizer = Nadam(learning_rate=learning_rate)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "param_grid = {'learning_rate': [.001],\n",
        "              'epochs': [100],\n",
        "              'batch_size': [10, 32],\n",
        "              'init': [ 'uniform']\n",
        "              }\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-3)\n",
        "grid_result = grid.fit(X_norm, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8166964530944825 using {'batch_size': 32, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001}\n",
            "Means: 0.8151353478431702, Stdev: 0.0038631967523415456 with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001}\n",
            "Means: 0.8166964530944825, Stdev: 0.0034251548188273698 with: {'batch_size': 32, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qCYCIXduZnM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "18515175-4129-454b-9df5-9d8cebdfcd88"
      },
      "source": [
        "# early stopping, manual time\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=20)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=X_norm[0].shape))\n",
        "model.add(Dense(20, activation='selu'))\n",
        "Dropout(.1)\n",
        "model.add(Dense(20, activation='selu'))\n",
        "Dropout(.1),\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "optimizer= Nadam(learning_rate=0.0012)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_norm, y, validation_split=0.20, epochs=100, callbacks=[stop])\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7810 - val_loss: 0.4050 - val_accuracy: 0.8062\n",
            "Epoch 2/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8149 - val_loss: 0.4063 - val_accuracy: 0.8077\n",
            "Epoch 3/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8172 - val_loss: 0.3992 - val_accuracy: 0.8126\n",
            "Epoch 4/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8188 - val_loss: 0.4105 - val_accuracy: 0.8062\n",
            "Epoch 5/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8204 - val_loss: 0.3998 - val_accuracy: 0.8119\n",
            "Epoch 6/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8213 - val_loss: 0.3986 - val_accuracy: 0.8126\n",
            "Epoch 7/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8198 - val_loss: 0.4025 - val_accuracy: 0.8077\n",
            "Epoch 8/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8229 - val_loss: 0.3980 - val_accuracy: 0.8141\n",
            "Epoch 9/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8227 - val_loss: 0.4044 - val_accuracy: 0.8055\n",
            "Epoch 10/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8229 - val_loss: 0.4105 - val_accuracy: 0.8062\n",
            "Epoch 11/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8193 - val_loss: 0.4023 - val_accuracy: 0.8077\n",
            "Epoch 12/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8191 - val_loss: 0.3978 - val_accuracy: 0.8112\n",
            "Epoch 13/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8237 - val_loss: 0.4015 - val_accuracy: 0.8084\n",
            "Epoch 14/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8252 - val_loss: 0.4033 - val_accuracy: 0.8148\n",
            "Epoch 15/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8223 - val_loss: 0.3973 - val_accuracy: 0.8098\n",
            "Epoch 16/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8257 - val_loss: 0.4003 - val_accuracy: 0.8126\n",
            "Epoch 17/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8243 - val_loss: 0.4024 - val_accuracy: 0.8091\n",
            "Epoch 18/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8266 - val_loss: 0.4010 - val_accuracy: 0.8105\n",
            "Epoch 19/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8252 - val_loss: 0.3991 - val_accuracy: 0.8077\n",
            "Epoch 20/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8239 - val_loss: 0.3991 - val_accuracy: 0.8112\n",
            "Epoch 21/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8287 - val_loss: 0.4028 - val_accuracy: 0.8091\n",
            "Epoch 22/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8250 - val_loss: 0.4004 - val_accuracy: 0.8098\n",
            "Epoch 23/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8277 - val_loss: 0.4041 - val_accuracy: 0.8034\n",
            "Epoch 24/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8268 - val_loss: 0.4037 - val_accuracy: 0.8091\n",
            "Epoch 25/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8266 - val_loss: 0.3987 - val_accuracy: 0.8084\n",
            "Epoch 26/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8285 - val_loss: 0.4027 - val_accuracy: 0.8119\n",
            "Epoch 27/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8273 - val_loss: 0.4020 - val_accuracy: 0.8091\n",
            "Epoch 28/100\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8305 - val_loss: 0.4016 - val_accuracy: 0.8084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f334661a898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDuhnSH-LDfc",
        "colab_type": "text"
      },
      "source": [
        "will not have a perceptron by scratch. \n",
        "Emulate perceptron architecture in keras, know the architecture of a perceptron\n",
        "estimate  a model, with keras, hyperparam choices\n",
        "basic info of perceptrons, why can't XOR gate solve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FfZRtJ7MCN3x"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
        "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
        "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
        "- Study for the Sprint Challenge\n",
        " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
        " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
      ]
    }
  ]
}