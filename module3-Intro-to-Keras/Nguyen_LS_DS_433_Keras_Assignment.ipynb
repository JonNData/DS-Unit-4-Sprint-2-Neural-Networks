{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nguyen_LS_DS_433_Keras_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "U4-S2-NN (Python3)",
      "language": "python",
      "name": "u4-sprint2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonNData/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/module3-Intro-to-Keras/Nguyen_LS_DS_433_Keras_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Neural Network Framework (Keras)\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbujZ7W_CRdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "norm = Normalizer()\n",
        "norm.fit(X_train)\n",
        "\n",
        "X_train = norm.transform(X_train)\n",
        "X_test = norm.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBpEJsfwDquF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ffb66433-3f09-4e93-c72d-45c91f825423"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.41189924e-03, 0.00000000e+00, 1.59296858e-02, ...,\n",
              "        4.10962409e-02, 7.76718953e-01, 3.66343633e-02],\n",
              "       [4.07923050e-05, 1.54587284e-01, 3.80378407e-03, ...,\n",
              "        2.75446433e-02, 7.40857215e-01, 5.82747215e-03],\n",
              "       [6.34505528e-03, 0.00000000e+00, 2.34463745e-02, ...,\n",
              "        2.61666721e-02, 4.86441025e-01, 4.22293817e-03],\n",
              "       ...,\n",
              "       [7.29281484e-05, 7.36435428e-02, 1.27508534e-02, ...,\n",
              "        3.55593107e-02, 7.62210668e-01, 1.64751126e-02],\n",
              "       [4.37205159e-03, 0.00000000e+00, 3.98313637e-02, ...,\n",
              "        2.99040371e-02, 5.32881804e-01, 3.21214113e-02],\n",
              "       [3.09311543e-05, 1.28969372e-01, 6.29800433e-03, ...,\n",
              "        3.35320367e-02, 8.09712706e-01, 9.41476414e-03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sORAR1nkCRdz",
        "colab_type": "code",
        "outputId": "490338f0-adc5-4b68-e448-1d11a0cd08ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (102, 13), (404,), (102,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txyp3E76DY1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "493ab805-185b-4abd-e24a-7c70068e4d33"
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTXAn_OfD3FV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6630d7da-3297-4415-92b6-3ef449de13c2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=(13,)))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "Dense(1, activation=\"relu\")\n",
        "                    \n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=200, validation_data=(X_test,y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 580.6384 - mse: 580.2256 - val_loss: 692.6382 - val_mse: 608.4952\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 577.0717 - mse: 577.9316 - val_loss: 689.8130 - val_mse: 605.8663\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 579.5499 - mse: 575.1408 - val_loss: 686.3481 - val_mse: 602.6434\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 571.3158 - mse: 571.7401 - val_loss: 682.1933 - val_mse: 598.7727\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 570.4741 - mse: 567.7205 - val_loss: 677.3829 - val_mse: 594.2852\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 564.2881 - mse: 563.1091 - val_loss: 671.8625 - val_mse: 589.1366\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 554.0682 - mse: 557.8210 - val_loss: 665.6660 - val_mse: 583.3595\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 552.6874 - mse: 551.9440 - val_loss: 658.7643 - val_mse: 576.9271\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 540.9522 - mse: 545.3909 - val_loss: 651.1769 - val_mse: 569.8596\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 540.4935 - mse: 538.2706 - val_loss: 642.8913 - val_mse: 562.1456\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 525.4901 - mse: 530.6052 - val_loss: 633.8491 - val_mse: 553.7319\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 519.9668 - mse: 522.1884 - val_loss: 624.3418 - val_mse: 544.8936\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 516.0683 - mse: 513.2767 - val_loss: 614.2749 - val_mse: 535.5428\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 500.1837 - mse: 504.0526 - val_loss: 603.4349 - val_mse: 525.4834\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 491.5580 - mse: 494.1588 - val_loss: 592.1899 - val_mse: 515.0592\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 488.5722 - mse: 483.9072 - val_loss: 580.5028 - val_mse: 504.2365\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 475.1343 - mse: 473.1763 - val_loss: 568.4227 - val_mse: 493.0640\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 461.1265 - mse: 462.1782 - val_loss: 555.9536 - val_mse: 481.5470\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 456.8174 - mse: 451.0127 - val_loss: 543.0913 - val_mse: 469.6822\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 435.4916 - mse: 439.5052 - val_loss: 529.9705 - val_mse: 457.5996\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 427.2384 - mse: 427.8294 - val_loss: 516.7899 - val_mse: 445.4823\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 418.9134 - mse: 416.0174 - val_loss: 503.5442 - val_mse: 433.3279\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 402.2271 - mse: 404.3218 - val_loss: 490.0282 - val_mse: 420.9498\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 396.8216 - mse: 392.4889 - val_loss: 476.5656 - val_mse: 408.6471\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 378.4289 - mse: 380.7012 - val_loss: 463.1068 - val_mse: 396.3771\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 375.9285 - mse: 368.9190 - val_loss: 449.9031 - val_mse: 384.3695\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 357.1178 - mse: 357.4860 - val_loss: 436.5909 - val_mse: 372.2940\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 344.6406 - mse: 346.0304 - val_loss: 423.6526 - val_mse: 360.5930\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 337.4208 - mse: 334.9601 - val_loss: 410.9550 - val_mse: 349.1471\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 323.0047 - mse: 324.2063 - val_loss: 398.4290 - val_mse: 337.8928\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 312.1994 - mse: 313.6064 - val_loss: 386.4320 - val_mse: 327.1534\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 303.8605 - mse: 303.5615 - val_loss: 374.7320 - val_mse: 316.7207\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 294.9125 - mse: 293.8117 - val_loss: 363.4398 - val_mse: 306.6939\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 281.3109 - mse: 284.5447 - val_loss: 352.5015 - val_mse: 297.0255\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 277.1293 - mse: 275.6467 - val_loss: 342.1457 - val_mse: 287.9174\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 269.9116 - mse: 267.1828 - val_loss: 332.2601 - val_mse: 279.2681\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 261.2156 - mse: 259.2385 - val_loss: 322.7402 - val_mse: 270.9872\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 251.9655 - mse: 251.7694 - val_loss: 313.7078 - val_mse: 263.1799\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 245.5401 - mse: 244.7019 - val_loss: 305.2920 - val_mse: 255.9524\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 238.2806 - mse: 238.1832 - val_loss: 297.3919 - val_mse: 249.2169\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 235.5335 - mse: 232.0939 - val_loss: 290.0932 - val_mse: 243.0412\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 228.7801 - mse: 226.5961 - val_loss: 283.1083 - val_mse: 237.1810\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 220.4269 - mse: 221.5402 - val_loss: 276.5493 - val_mse: 231.7272\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 216.6459 - mse: 216.7334 - val_loss: 270.7498 - val_mse: 226.9513\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 212.1772 - mse: 212.5615 - val_loss: 265.2696 - val_mse: 222.4837\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 207.4789 - mse: 208.7883 - val_loss: 260.1718 - val_mse: 218.3740\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 204.9164 - mse: 205.2661 - val_loss: 255.7127 - val_mse: 214.8202\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 200.1274 - mse: 202.2453 - val_loss: 251.5674 - val_mse: 211.5582\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 198.4337 - mse: 199.5554 - val_loss: 247.7950 - val_mse: 208.6275\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 196.1913 - mse: 197.1739 - val_loss: 244.3379 - val_mse: 205.9805\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 194.1638 - mse: 194.9320 - val_loss: 241.3765 - val_mse: 203.7429\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 193.2488 - mse: 193.1118 - val_loss: 238.5646 - val_mse: 201.6520\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 190.2013 - mse: 191.4826 - val_loss: 236.0099 - val_mse: 199.7828\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 187.9835 - mse: 189.9834 - val_loss: 233.8755 - val_mse: 198.2443\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 188.1517 - mse: 188.7863 - val_loss: 231.8706 - val_mse: 196.8238\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 187.8437 - mse: 187.6487 - val_loss: 230.1294 - val_mse: 195.6088\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 185.5223 - mse: 186.7283 - val_loss: 228.4675 - val_mse: 194.4722\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 184.1793 - mse: 185.8675 - val_loss: 227.1129 - val_mse: 193.5547\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 188.2547 - mse: 185.1807 - val_loss: 225.8168 - val_mse: 192.6966\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 185.9455 - mse: 184.5605 - val_loss: 224.5858 - val_mse: 191.8978\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 183.2181 - mse: 184.0024 - val_loss: 223.4994 - val_mse: 191.2035\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 184.4794 - mse: 183.5216 - val_loss: 222.6175 - val_mse: 190.6451\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 182.7463 - mse: 183.1357 - val_loss: 221.7611 - val_mse: 190.1149\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 184.7565 - mse: 182.7926 - val_loss: 221.0078 - val_mse: 189.6495\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 182.9636 - mse: 182.4505 - val_loss: 220.4283 - val_mse: 189.2876\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 182.8204 - mse: 182.2003 - val_loss: 219.8206 - val_mse: 188.9176\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 181.0601 - mse: 181.9594 - val_loss: 219.3140 - val_mse: 188.6058\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 184.7641 - mse: 181.7471 - val_loss: 218.8582 - val_mse: 188.3265\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 184.5891 - mse: 181.5491 - val_loss: 218.4307 - val_mse: 188.0624\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 180.3973 - mse: 181.3732 - val_loss: 217.9549 - val_mse: 187.7841\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 185.9034 - mse: 181.1883 - val_loss: 217.6855 - val_mse: 187.6021\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 181.9957 - mse: 181.0448 - val_loss: 217.2728 - val_mse: 187.3587\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 180.4504 - mse: 180.8971 - val_loss: 216.9478 - val_mse: 187.1536\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 178.7338 - mse: 180.7500 - val_loss: 216.7317 - val_mse: 186.9976\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 181.6826 - mse: 180.6246 - val_loss: 216.5098 - val_mse: 186.8382\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.0505 - mse: 180.5074 - val_loss: 216.2355 - val_mse: 186.6583\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.2636 - mse: 180.3708 - val_loss: 216.0811 - val_mse: 186.5252\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 182.7612 - mse: 180.2523 - val_loss: 215.9641 - val_mse: 186.4075\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.9298 - mse: 180.1474 - val_loss: 215.6622 - val_mse: 186.2206\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 180.0082 - mse: 180.0015 - val_loss: 215.5426 - val_mse: 186.0992\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.8439 - mse: 179.8889 - val_loss: 215.3644 - val_mse: 185.9524\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 180.3616 - mse: 179.7682 - val_loss: 215.2117 - val_mse: 185.8193\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 180.2578 - mse: 179.6440 - val_loss: 215.0854 - val_mse: 185.6966\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 178.2107 - mse: 179.5322 - val_loss: 215.0078 - val_mse: 185.5864\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 178.0289 - mse: 179.4105 - val_loss: 214.8492 - val_mse: 185.4515\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.8340 - mse: 179.2944 - val_loss: 214.7950 - val_mse: 185.3454\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.8177 - mse: 179.1868 - val_loss: 214.6148 - val_mse: 185.1985\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 178.6257 - mse: 179.0473 - val_loss: 214.5153 - val_mse: 185.0836\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.0259 - mse: 178.9314 - val_loss: 214.4232 - val_mse: 184.9581\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.6552 - mse: 178.8091 - val_loss: 214.4062 - val_mse: 184.8680\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.8568 - mse: 178.7022 - val_loss: 214.1027 - val_mse: 184.6815\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.4637 - mse: 178.5634 - val_loss: 213.9613 - val_mse: 184.5455\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.1449 - mse: 178.4329 - val_loss: 213.9312 - val_mse: 184.4424\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 176.9527 - mse: 178.3086 - val_loss: 213.8600 - val_mse: 184.3248\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 178.0962 - mse: 178.1790 - val_loss: 213.7402 - val_mse: 184.1893\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.6419 - mse: 178.0457 - val_loss: 213.6032 - val_mse: 184.0539\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 178.8210 - mse: 177.9128 - val_loss: 213.4349 - val_mse: 183.9057\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.6619 - mse: 177.7841 - val_loss: 213.3034 - val_mse: 183.7692\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 176.1986 - mse: 177.6510 - val_loss: 213.1545 - val_mse: 183.6179\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 176.0907 - mse: 177.5136 - val_loss: 213.0164 - val_mse: 183.4738\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.8438 - mse: 177.3794 - val_loss: 213.0060 - val_mse: 183.3714\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.9656 - mse: 177.2537 - val_loss: 212.7998 - val_mse: 183.2057\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 175.6572 - mse: 177.1097 - val_loss: 212.6533 - val_mse: 183.0553\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 178.3410 - mse: 176.9651 - val_loss: 212.5521 - val_mse: 182.9265\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 175.0659 - mse: 176.8351 - val_loss: 212.3941 - val_mse: 182.7706\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.1945 - mse: 176.6910 - val_loss: 212.3333 - val_mse: 182.6468\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 175.8676 - mse: 176.5532 - val_loss: 212.1500 - val_mse: 182.4874\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.9303 - mse: 176.4151 - val_loss: 212.1158 - val_mse: 182.3698\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 174.0012 - mse: 176.2788 - val_loss: 212.0222 - val_mse: 182.2350\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 174.4165 - mse: 176.1342 - val_loss: 211.9301 - val_mse: 182.1045\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 178.1540 - mse: 176.0043 - val_loss: 211.8544 - val_mse: 181.9769\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 175.8817 - mse: 175.8591 - val_loss: 211.6256 - val_mse: 181.7990\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 177.1658 - mse: 175.7181 - val_loss: 211.5637 - val_mse: 181.6741\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 173.9898 - mse: 175.5742 - val_loss: 211.3651 - val_mse: 181.5059\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 174.5134 - mse: 175.4384 - val_loss: 211.2109 - val_mse: 181.3534\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 176.2327 - mse: 175.2989 - val_loss: 211.1190 - val_mse: 181.2149\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.9327 - mse: 175.1783 - val_loss: 210.8920 - val_mse: 181.0387\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 173.9494 - mse: 175.0201 - val_loss: 210.9966 - val_mse: 180.9685\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 174.5876 - mse: 174.8782 - val_loss: 210.8158 - val_mse: 180.8055\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 174.7896 - mse: 174.7489 - val_loss: 210.7945 - val_mse: 180.6907\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 173.8901 - mse: 174.6134 - val_loss: 210.5843 - val_mse: 180.5180\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 174.7294 - mse: 174.4685 - val_loss: 210.4121 - val_mse: 180.3643\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 175.3135 - mse: 174.3249 - val_loss: 210.3233 - val_mse: 180.2366\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 174.6717 - mse: 174.2088 - val_loss: 210.3432 - val_mse: 180.1370\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 175.6685 - mse: 174.0540 - val_loss: 210.1515 - val_mse: 179.9706\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 174.9979 - mse: 173.9134 - val_loss: 210.0047 - val_mse: 179.8251\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 173.3713 - mse: 173.7849 - val_loss: 209.8715 - val_mse: 179.6737\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.3321 - mse: 173.6457 - val_loss: 209.7548 - val_mse: 179.5334\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.4661 - mse: 173.5112 - val_loss: 209.5578 - val_mse: 179.3743\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.2113 - mse: 173.3775 - val_loss: 209.5150 - val_mse: 179.2562\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.5644 - mse: 173.2529 - val_loss: 209.4814 - val_mse: 179.1420\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 172.7477 - mse: 173.1098 - val_loss: 209.3468 - val_mse: 179.0002\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 173.2944 - mse: 172.9866 - val_loss: 209.2585 - val_mse: 178.8752\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.2672 - mse: 172.8537 - val_loss: 209.1190 - val_mse: 178.7314\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 173.5522 - mse: 172.7240 - val_loss: 208.9702 - val_mse: 178.5844\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.8132 - mse: 172.5934 - val_loss: 208.7966 - val_mse: 178.4307\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.4128 - mse: 172.4642 - val_loss: 208.6957 - val_mse: 178.3017\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.0630 - mse: 172.3431 - val_loss: 208.5403 - val_mse: 178.1552\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.5203 - mse: 172.2218 - val_loss: 208.3978 - val_mse: 178.0163\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.4577 - mse: 172.0928 - val_loss: 208.2895 - val_mse: 177.8839\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.7053 - mse: 171.9624 - val_loss: 208.2686 - val_mse: 177.7783\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 173.1812 - mse: 171.8689 - val_loss: 208.0512 - val_mse: 177.6149\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.6034 - mse: 171.7210 - val_loss: 208.0163 - val_mse: 177.5110\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.6797 - mse: 171.5916 - val_loss: 207.8922 - val_mse: 177.3770\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.2612 - mse: 171.4773 - val_loss: 207.7025 - val_mse: 177.2277\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 173.4951 - mse: 171.3714 - val_loss: 207.6184 - val_mse: 177.1077\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.3276 - mse: 171.2314 - val_loss: 207.5079 - val_mse: 176.9816\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 173.4605 - mse: 171.1235 - val_loss: 207.5466 - val_mse: 176.8962\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.4912 - mse: 170.9986 - val_loss: 207.3748 - val_mse: 176.7555\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.5512 - mse: 170.8970 - val_loss: 207.3640 - val_mse: 176.6629\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 169.1183 - mse: 170.7679 - val_loss: 207.1470 - val_mse: 176.5076\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.4671 - mse: 170.6680 - val_loss: 207.1405 - val_mse: 176.4125\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.1417 - mse: 170.5605 - val_loss: 206.9439 - val_mse: 176.2672\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 168.9782 - mse: 170.4285 - val_loss: 206.8878 - val_mse: 176.1620\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 170.4966 - mse: 170.3219 - val_loss: 206.9131 - val_mse: 176.0831\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.2026 - mse: 170.2153 - val_loss: 206.7998 - val_mse: 175.9559\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.1409 - mse: 170.1324 - val_loss: 206.8831 - val_mse: 175.8997\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.2899 - mse: 169.9941 - val_loss: 206.5988 - val_mse: 175.7337\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.1486 - mse: 169.8914 - val_loss: 206.4196 - val_mse: 175.5952\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 170.9974 - mse: 169.7856 - val_loss: 206.3528 - val_mse: 175.4917\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.1875 - mse: 169.7089 - val_loss: 206.1001 - val_mse: 175.3311\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.4330 - mse: 169.5817 - val_loss: 206.2353 - val_mse: 175.2921\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.1596 - mse: 169.4840 - val_loss: 206.1414 - val_mse: 175.1855\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 168.7662 - mse: 169.4213 - val_loss: 205.8148 - val_mse: 175.0086\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 167.5268 - mse: 169.2912 - val_loss: 205.9351 - val_mse: 174.9600\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 167.6688 - mse: 169.1847 - val_loss: 205.9385 - val_mse: 174.8775\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 167.7567 - mse: 169.0958 - val_loss: 205.7471 - val_mse: 174.7447\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.1571 - mse: 169.0026 - val_loss: 205.8716 - val_mse: 174.7091\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.5526 - mse: 168.8973 - val_loss: 205.7526 - val_mse: 174.5972\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.8632 - mse: 168.7980 - val_loss: 205.5155 - val_mse: 174.4491\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 168.3376 - mse: 168.7024 - val_loss: 205.4112 - val_mse: 174.3493\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.4987 - mse: 168.6338 - val_loss: 205.3707 - val_mse: 174.2607\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 170.6646 - mse: 168.5212 - val_loss: 205.1107 - val_mse: 174.1150\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.7783 - mse: 168.4482 - val_loss: 204.9071 - val_mse: 173.9827\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 170.3979 - mse: 168.3576 - val_loss: 204.9715 - val_mse: 173.9326\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 167.3802 - mse: 168.2721 - val_loss: 204.8386 - val_mse: 173.8187\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 167.1444 - mse: 168.1795 - val_loss: 204.8061 - val_mse: 173.7385\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.6370 - mse: 168.0997 - val_loss: 204.7846 - val_mse: 173.6619\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 166.1939 - mse: 168.0073 - val_loss: 204.7541 - val_mse: 173.5896\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.2003 - mse: 167.9413 - val_loss: 204.7585 - val_mse: 173.5239\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.6016 - mse: 167.8438 - val_loss: 204.6817 - val_mse: 173.4375\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 168.1206 - mse: 167.7813 - val_loss: 204.4894 - val_mse: 173.3077\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 165.5589 - mse: 167.6961 - val_loss: 204.3470 - val_mse: 173.2024\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.7685 - mse: 167.6051 - val_loss: 204.3596 - val_mse: 173.1485\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.9705 - mse: 167.5378 - val_loss: 204.5043 - val_mse: 173.1293\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.7858 - mse: 167.4635 - val_loss: 204.4175 - val_mse: 173.0448\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 165.8318 - mse: 167.3912 - val_loss: 204.2979 - val_mse: 172.9466\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 166.3504 - mse: 167.3129 - val_loss: 204.2604 - val_mse: 172.8768\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 166.7975 - mse: 167.2535 - val_loss: 204.2558 - val_mse: 172.8199\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 167.6423 - mse: 167.1777 - val_loss: 204.1551 - val_mse: 172.7275\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 168.0022 - mse: 167.1110 - val_loss: 204.0243 - val_mse: 172.6317\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 165.5041 - mse: 167.0352 - val_loss: 204.0005 - val_mse: 172.5623\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 172.2785 - mse: 166.9807 - val_loss: 204.1880 - val_mse: 172.5689\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 165.6892 - mse: 166.9025 - val_loss: 203.8220 - val_mse: 172.3983\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.9398 - mse: 166.8355 - val_loss: 203.8398 - val_mse: 172.3506\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 169.7757 - mse: 166.7645 - val_loss: 203.7975 - val_mse: 172.2825\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 168.1044 - mse: 166.6971 - val_loss: 203.4571 - val_mse: 172.1350\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.9879 - mse: 166.6388 - val_loss: 203.4932 - val_mse: 172.0908\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 166.9130 - mse: 166.5645 - val_loss: 203.3717 - val_mse: 172.0068\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 164.9309 - mse: 166.5087 - val_loss: 203.3182 - val_mse: 171.9374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f13a8853eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "41ChmeyZCRd3",
        "colab_type": "code",
        "outputId": "91cf8ddb-bb3a-424a-84cc-8eb13b7ec9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(13,)),\n",
        "    Dense(15, activation=\"relu\"),\n",
        "    Dense(1, activation=\"relu\")\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "model.fit(x=X_train, \n",
        "        y=y_train, \n",
        "        epochs=150, \n",
        "        validation_data=(X_test, y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 565.8996 - mse: 571.2064 - val_loss: 680.6891 - val_mse: 597.2583\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 566.5536 - mse: 565.6519 - val_loss: 674.3757 - val_mse: 591.3954\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 565.9410 - mse: 559.7994 - val_loss: 667.9562 - val_mse: 585.3973\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 558.1086 - mse: 553.8999 - val_loss: 661.2964 - val_mse: 579.1769\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 546.5894 - mse: 547.8298 - val_loss: 654.5442 - val_mse: 572.8759\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 542.0881 - mse: 541.7883 - val_loss: 647.8620 - val_mse: 566.6362\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 534.8443 - mse: 535.7513 - val_loss: 641.0650 - val_mse: 560.2876\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 528.7955 - mse: 529.5086 - val_loss: 634.0795 - val_mse: 553.7673\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 523.4053 - mse: 523.1182 - val_loss: 626.7219 - val_mse: 546.9067\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 521.1625 - mse: 516.2975 - val_loss: 619.1487 - val_mse: 539.8517\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 508.3766 - mse: 509.3372 - val_loss: 611.1780 - val_mse: 532.4305\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 501.7837 - mse: 502.0733 - val_loss: 602.9160 - val_mse: 524.7430\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 497.2586 - mse: 494.4860 - val_loss: 594.4250 - val_mse: 516.8472\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 489.0963 - mse: 486.6711 - val_loss: 585.6569 - val_mse: 508.6995\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 480.1958 - mse: 478.6508 - val_loss: 576.5716 - val_mse: 500.2623\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 468.5195 - mse: 470.4614 - val_loss: 567.1494 - val_mse: 491.5195\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 468.4119 - mse: 461.8954 - val_loss: 557.6117 - val_mse: 482.6763\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 452.7064 - mse: 453.2405 - val_loss: 547.7427 - val_mse: 473.5328\n",
            "Epoch 19/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 443.5891 - mse: 444.3259 - val_loss: 537.7361 - val_mse: 464.2699\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 434.8231 - mse: 435.2575 - val_loss: 527.5569 - val_mse: 454.8552\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 428.3368 - mse: 426.0623 - val_loss: 517.1742 - val_mse: 445.2607\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 415.5144 - mse: 416.7158 - val_loss: 506.5867 - val_mse: 435.4870\n",
            "Epoch 23/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 409.5297 - mse: 407.3106 - val_loss: 495.7953 - val_mse: 425.5352\n",
            "Epoch 24/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 398.4333 - mse: 397.6247 - val_loss: 484.9959 - val_mse: 415.5876\n",
            "Epoch 25/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 384.5243 - mse: 388.0094 - val_loss: 474.0359 - val_mse: 405.5027\n",
            "Epoch 26/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 374.1882 - mse: 378.3267 - val_loss: 462.9883 - val_mse: 395.3504\n",
            "Epoch 27/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 365.8534 - mse: 368.4980 - val_loss: 452.0114 - val_mse: 385.2761\n",
            "Epoch 28/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 355.6466 - mse: 358.7381 - val_loss: 440.9581 - val_mse: 375.1444\n",
            "Epoch 29/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 346.8084 - mse: 349.0685 - val_loss: 429.7357 - val_mse: 364.8711\n",
            "Epoch 30/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 333.7893 - mse: 339.2675 - val_loss: 418.5484 - val_mse: 354.6457\n",
            "Epoch 31/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 329.5458 - mse: 329.4215 - val_loss: 407.5611 - val_mse: 344.6197\n",
            "Epoch 32/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 318.9380 - mse: 319.7657 - val_loss: 396.4796 - val_mse: 334.5230\n",
            "Epoch 33/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 312.9966 - mse: 310.0194 - val_loss: 385.5323 - val_mse: 324.5661\n",
            "Epoch 34/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 306.5099 - mse: 300.4460 - val_loss: 374.5857 - val_mse: 314.6272\n",
            "Epoch 35/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 290.9491 - mse: 290.9583 - val_loss: 363.6212 - val_mse: 304.6911\n",
            "Epoch 36/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 282.5558 - mse: 281.5559 - val_loss: 352.7894 - val_mse: 294.8942\n",
            "Epoch 37/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 271.2495 - mse: 272.3029 - val_loss: 342.0745 - val_mse: 285.2249\n",
            "Epoch 38/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 263.5859 - mse: 263.1029 - val_loss: 331.6620 - val_mse: 275.8483\n",
            "Epoch 39/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 257.7495 - mse: 254.3026 - val_loss: 321.2081 - val_mse: 266.4558\n",
            "Epoch 40/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 244.4014 - mse: 245.4759 - val_loss: 310.9731 - val_mse: 257.2827\n",
            "Epoch 41/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 241.1143 - mse: 236.8507 - val_loss: 301.0563 - val_mse: 248.4175\n",
            "Epoch 42/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 231.3035 - mse: 228.5284 - val_loss: 291.2308 - val_mse: 239.6593\n",
            "Epoch 43/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 216.8407 - mse: 220.2797 - val_loss: 281.7292 - val_mse: 231.2130\n",
            "Epoch 44/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 210.1865 - mse: 212.4096 - val_loss: 272.4809 - val_mse: 223.0159\n",
            "Epoch 45/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 202.9562 - mse: 204.7445 - val_loss: 263.5255 - val_mse: 215.1050\n",
            "Epoch 46/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 197.0706 - mse: 197.3828 - val_loss: 254.7655 - val_mse: 207.3906\n",
            "Epoch 47/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 190.3120 - mse: 190.2263 - val_loss: 246.2225 - val_mse: 199.8936\n",
            "Epoch 48/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 183.9753 - mse: 183.3085 - val_loss: 237.9637 - val_mse: 192.6716\n",
            "Epoch 49/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 179.3268 - mse: 176.6333 - val_loss: 229.9691 - val_mse: 185.7089\n",
            "Epoch 50/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 171.9514 - mse: 170.1861 - val_loss: 222.2415 - val_mse: 179.0073\n",
            "Epoch 51/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 161.9874 - mse: 164.1964 - val_loss: 214.5652 - val_mse: 172.3779\n",
            "Epoch 52/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 155.3901 - mse: 158.1092 - val_loss: 207.5755 - val_mse: 166.3685\n",
            "Epoch 53/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 155.6578 - mse: 152.6587 - val_loss: 200.7169 - val_mse: 160.5002\n",
            "Epoch 54/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 146.7219 - mse: 147.2323 - val_loss: 194.2274 - val_mse: 154.9746\n",
            "Epoch 55/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 143.0306 - mse: 142.2573 - val_loss: 187.9256 - val_mse: 149.6369\n",
            "Epoch 56/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 136.5413 - mse: 137.4543 - val_loss: 181.9385 - val_mse: 144.5955\n",
            "Epoch 57/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 133.9725 - mse: 132.9545 - val_loss: 176.1815 - val_mse: 139.7742\n",
            "Epoch 58/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 131.2731 - mse: 128.5652 - val_loss: 170.8638 - val_mse: 135.3479\n",
            "Epoch 59/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 123.9603 - mse: 124.7100 - val_loss: 165.5517 - val_mse: 130.9557\n",
            "Epoch 60/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 118.9771 - mse: 120.8449 - val_loss: 160.7156 - val_mse: 126.9855\n",
            "Epoch 61/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 118.2341 - mse: 117.4132 - val_loss: 156.0363 - val_mse: 123.1706\n",
            "Epoch 62/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 111.9153 - mse: 114.0708 - val_loss: 151.7023 - val_mse: 119.6618\n",
            "Epoch 63/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 109.4206 - mse: 111.0426 - val_loss: 147.6338 - val_mse: 116.3934\n",
            "Epoch 64/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 106.4925 - mse: 108.1840 - val_loss: 143.8607 - val_mse: 113.3872\n",
            "Epoch 65/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 104.9024 - mse: 105.6415 - val_loss: 140.1836 - val_mse: 110.4816\n",
            "Epoch 66/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 105.5413 - mse: 103.1268 - val_loss: 136.8868 - val_mse: 107.9007\n",
            "Epoch 67/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 101.5668 - mse: 100.9206 - val_loss: 133.6478 - val_mse: 105.3877\n",
            "Epoch 68/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 98.9857 - mse: 98.8006 - val_loss: 130.6953 - val_mse: 103.1192\n",
            "Epoch 69/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 95.0633 - mse: 96.9873 - val_loss: 127.7945 - val_mse: 100.9119\n",
            "Epoch 70/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 96.3657 - mse: 95.1140 - val_loss: 125.3478 - val_mse: 99.0686\n",
            "Epoch 71/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 92.4043 - mse: 93.5646 - val_loss: 122.8689 - val_mse: 97.2227\n",
            "Epoch 72/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 92.0023 - mse: 92.0998 - val_loss: 120.5550 - val_mse: 95.5185\n",
            "Epoch 73/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 91.1196 - mse: 90.7311 - val_loss: 118.4393 - val_mse: 93.9784\n",
            "Epoch 74/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 94.7465 - mse: 89.4563 - val_loss: 116.5583 - val_mse: 92.6254\n",
            "Epoch 75/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 87.2957 - mse: 88.4083 - val_loss: 114.5977 - val_mse: 91.2349\n",
            "Epoch 76/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 85.8356 - mse: 87.3642 - val_loss: 112.8895 - val_mse: 90.0366\n",
            "Epoch 77/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 85.7576 - mse: 86.4175 - val_loss: 111.4185 - val_mse: 89.0160\n",
            "Epoch 78/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 86.2564 - mse: 85.6208 - val_loss: 110.0300 - val_mse: 88.0657\n",
            "Epoch 79/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 83.5925 - mse: 84.8669 - val_loss: 108.7224 - val_mse: 87.1805\n",
            "Epoch 80/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 84.4156 - mse: 84.2000 - val_loss: 107.5314 - val_mse: 86.3851\n",
            "Epoch 81/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 83.1072 - mse: 83.5769 - val_loss: 106.4104 - val_mse: 85.6455\n",
            "Epoch 82/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 82.7457 - mse: 83.0375 - val_loss: 105.3273 - val_mse: 84.9417\n",
            "Epoch 83/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 83.4884 - mse: 82.5568 - val_loss: 104.3125 - val_mse: 84.2910\n",
            "Epoch 84/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 82.7752 - mse: 82.0887 - val_loss: 103.4091 - val_mse: 83.7160\n",
            "Epoch 85/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 82.5914 - mse: 81.6658 - val_loss: 102.5839 - val_mse: 83.1977\n",
            "Epoch 86/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 80.7724 - mse: 81.3080 - val_loss: 101.7806 - val_mse: 82.6989\n",
            "Epoch 87/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 80.1265 - mse: 80.9643 - val_loss: 101.0582 - val_mse: 82.2539\n",
            "Epoch 88/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 80.2008 - mse: 80.6450 - val_loss: 100.4799 - val_mse: 81.8956\n",
            "Epoch 89/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 79.3419 - mse: 80.4087 - val_loss: 99.7904 - val_mse: 81.4827\n",
            "Epoch 90/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 81.8560 - mse: 80.1299 - val_loss: 99.2574 - val_mse: 81.1606\n",
            "Epoch 91/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 80.5552 - mse: 79.8917 - val_loss: 98.7304 - val_mse: 80.8442\n",
            "Epoch 92/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 79.6262 - mse: 79.7069 - val_loss: 98.1509 - val_mse: 80.5067\n",
            "Epoch 93/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 79.4815 - mse: 79.4718 - val_loss: 97.7419 - val_mse: 80.2588\n",
            "Epoch 94/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 78.7631 - mse: 79.3117 - val_loss: 97.3104 - val_mse: 79.9984\n",
            "Epoch 95/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 78.5281 - mse: 79.1279 - val_loss: 96.9603 - val_mse: 79.7826\n",
            "Epoch 96/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 77.9437 - mse: 78.9720 - val_loss: 96.6067 - val_mse: 79.5611\n",
            "Epoch 97/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 79.6766 - mse: 78.8336 - val_loss: 96.2082 - val_mse: 79.3214\n",
            "Epoch 98/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 78.0097 - mse: 78.6638 - val_loss: 95.8673 - val_mse: 79.1073\n",
            "Epoch 99/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 78.2769 - mse: 78.4945 - val_loss: 95.5537 - val_mse: 78.8865\n",
            "Epoch 100/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 79.2647 - mse: 78.3211 - val_loss: 95.2119 - val_mse: 78.6220\n",
            "Epoch 101/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 76.4789 - mse: 78.1037 - val_loss: 95.0567 - val_mse: 78.4086\n",
            "Epoch 102/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 78.4629 - mse: 77.8979 - val_loss: 94.8150 - val_mse: 78.1744\n",
            "Epoch 103/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 76.0582 - mse: 77.6745 - val_loss: 94.5207 - val_mse: 77.9279\n",
            "Epoch 104/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 77.1699 - mse: 77.4672 - val_loss: 94.2688 - val_mse: 77.6834\n",
            "Epoch 105/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 77.0180 - mse: 77.2764 - val_loss: 94.1611 - val_mse: 77.4808\n",
            "Epoch 106/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 78.3616 - mse: 77.0436 - val_loss: 93.8046 - val_mse: 77.2086\n",
            "Epoch 107/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 79.6590 - mse: 76.8225 - val_loss: 93.5651 - val_mse: 76.9602\n",
            "Epoch 108/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 77.6361 - mse: 76.5927 - val_loss: 93.2896 - val_mse: 76.7058\n",
            "Epoch 109/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 75.3209 - mse: 76.3906 - val_loss: 92.9479 - val_mse: 76.4358\n",
            "Epoch 110/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 77.7072 - mse: 76.1594 - val_loss: 92.8889 - val_mse: 76.2418\n",
            "Epoch 111/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 77.0535 - mse: 75.9295 - val_loss: 92.5643 - val_mse: 75.9666\n",
            "Epoch 112/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 79.0784 - mse: 75.7000 - val_loss: 92.4129 - val_mse: 75.7496\n",
            "Epoch 113/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 77.7696 - mse: 75.4763 - val_loss: 92.1052 - val_mse: 75.4758\n",
            "Epoch 114/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 74.8458 - mse: 75.2553 - val_loss: 91.8187 - val_mse: 75.2077\n",
            "Epoch 115/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 76.0531 - mse: 75.0302 - val_loss: 91.5871 - val_mse: 74.9665\n",
            "Epoch 116/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 73.6482 - mse: 74.8127 - val_loss: 91.4644 - val_mse: 74.7590\n",
            "Epoch 117/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 73.6859 - mse: 74.5871 - val_loss: 91.1648 - val_mse: 74.5049\n",
            "Epoch 118/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 77.7831 - mse: 74.3797 - val_loss: 90.9754 - val_mse: 74.2571\n",
            "Epoch 119/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 76.5542 - mse: 74.1498 - val_loss: 90.8869 - val_mse: 74.0611\n",
            "Epoch 120/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 73.0151 - mse: 73.9281 - val_loss: 90.5401 - val_mse: 73.7769\n",
            "Epoch 121/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 73.1678 - mse: 73.6960 - val_loss: 90.3546 - val_mse: 73.5454\n",
            "Epoch 122/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 74.1807 - mse: 73.4776 - val_loss: 90.2771 - val_mse: 73.3570\n",
            "Epoch 123/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 73.1412 - mse: 73.2832 - val_loss: 89.8506 - val_mse: 73.0588\n",
            "Epoch 124/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 72.6320 - mse: 73.0493 - val_loss: 89.6973 - val_mse: 72.8355\n",
            "Epoch 125/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 74.3009 - mse: 72.8579 - val_loss: 89.7808 - val_mse: 72.6924\n",
            "Epoch 126/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 73.8809 - mse: 72.6087 - val_loss: 89.5095 - val_mse: 72.4338\n",
            "Epoch 127/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 72.1917 - mse: 72.3895 - val_loss: 89.2552 - val_mse: 72.1884\n",
            "Epoch 128/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 72.6978 - mse: 72.1868 - val_loss: 88.9429 - val_mse: 71.9260\n",
            "Epoch 129/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 72.1196 - mse: 71.9786 - val_loss: 88.7399 - val_mse: 71.6980\n",
            "Epoch 130/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 71.6957 - mse: 71.7663 - val_loss: 88.7355 - val_mse: 71.5434\n",
            "Epoch 131/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 71.5842 - mse: 71.5627 - val_loss: 88.5590 - val_mse: 71.3212\n",
            "Epoch 132/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 71.2062 - mse: 71.3572 - val_loss: 88.2682 - val_mse: 71.0666\n",
            "Epoch 133/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 71.6176 - mse: 71.1576 - val_loss: 88.1375 - val_mse: 70.8658\n",
            "Epoch 134/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 73.8489 - mse: 70.9452 - val_loss: 88.0918 - val_mse: 70.7054\n",
            "Epoch 135/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 70.6410 - mse: 70.7651 - val_loss: 87.8599 - val_mse: 70.4655\n",
            "Epoch 136/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 69.6732 - mse: 70.5536 - val_loss: 87.6921 - val_mse: 70.2610\n",
            "Epoch 137/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 68.7972 - mse: 70.3585 - val_loss: 87.5156 - val_mse: 70.0509\n",
            "Epoch 138/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 70.4076 - mse: 70.1671 - val_loss: 87.2919 - val_mse: 69.8290\n",
            "Epoch 139/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 69.6216 - mse: 70.0088 - val_loss: 87.3399 - val_mse: 69.6965\n",
            "Epoch 140/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 69.1248 - mse: 69.7868 - val_loss: 87.0108 - val_mse: 69.4458\n",
            "Epoch 141/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 68.9100 - mse: 69.6049 - val_loss: 86.7978 - val_mse: 69.2298\n",
            "Epoch 142/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 68.3656 - mse: 69.4138 - val_loss: 86.6995 - val_mse: 69.0490\n",
            "Epoch 143/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 69.6061 - mse: 69.2250 - val_loss: 86.4543 - val_mse: 68.8254\n",
            "Epoch 144/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 68.8941 - mse: 69.0516 - val_loss: 86.3135 - val_mse: 68.6376\n",
            "Epoch 145/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 68.7409 - mse: 68.8582 - val_loss: 86.1017 - val_mse: 68.4270\n",
            "Epoch 146/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 68.8041 - mse: 68.6846 - val_loss: 86.0128 - val_mse: 68.2633\n",
            "Epoch 147/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 68.6163 - mse: 68.5125 - val_loss: 85.7917 - val_mse: 68.0447\n",
            "Epoch 148/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 68.1675 - mse: 68.3894 - val_loss: 85.3920 - val_mse: 67.7797\n",
            "Epoch 149/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 68.2855 - mse: 68.1649 - val_loss: 85.3270 - val_mse: 67.6136\n",
            "Epoch 150/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 67.0162 - mse: 67.9835 - val_loss: 85.3205 - val_mse: 67.4810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f13acea6208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBALCcdtCRd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5bd95304-351d-477e-98b4-7b8f5400bd42"
      },
      "source": [
        "hist = model.history.history\n",
        "hist"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [580.638427734375,\n",
              "  577.0717163085938,\n",
              "  579.5498657226562,\n",
              "  571.3157958984375,\n",
              "  570.47412109375,\n",
              "  564.2881469726562,\n",
              "  554.0682373046875,\n",
              "  552.6874389648438,\n",
              "  540.9522094726562,\n",
              "  540.4934692382812,\n",
              "  525.4900512695312,\n",
              "  519.966796875,\n",
              "  516.0682983398438,\n",
              "  500.1837463378906,\n",
              "  491.5579528808594,\n",
              "  488.57220458984375,\n",
              "  475.13433837890625,\n",
              "  461.1264953613281,\n",
              "  456.8174133300781,\n",
              "  435.4915771484375,\n",
              "  427.2384338378906,\n",
              "  418.9134216308594,\n",
              "  402.22705078125,\n",
              "  396.8216247558594,\n",
              "  378.4288635253906,\n",
              "  375.92852783203125,\n",
              "  357.1177978515625,\n",
              "  344.64056396484375,\n",
              "  337.4207763671875,\n",
              "  323.0047302246094,\n",
              "  312.1993713378906,\n",
              "  303.86053466796875,\n",
              "  294.91253662109375,\n",
              "  281.3109436035156,\n",
              "  277.1292724609375,\n",
              "  269.9115905761719,\n",
              "  261.215576171875,\n",
              "  251.96551513671875,\n",
              "  245.54013061523438,\n",
              "  238.28057861328125,\n",
              "  235.5335235595703,\n",
              "  228.7801055908203,\n",
              "  220.42689514160156,\n",
              "  216.64593505859375,\n",
              "  212.17715454101562,\n",
              "  207.47889709472656,\n",
              "  204.91639709472656,\n",
              "  200.12741088867188,\n",
              "  198.43370056152344,\n",
              "  196.19126892089844,\n",
              "  194.16383361816406,\n",
              "  193.248779296875,\n",
              "  190.2013397216797,\n",
              "  187.98345947265625,\n",
              "  188.15174865722656,\n",
              "  187.84365844726562,\n",
              "  185.52230834960938,\n",
              "  184.17926025390625,\n",
              "  188.25466918945312,\n",
              "  185.94554138183594,\n",
              "  183.2180938720703,\n",
              "  184.47938537597656,\n",
              "  182.7462615966797,\n",
              "  184.75645446777344,\n",
              "  182.96356201171875,\n",
              "  182.82041931152344,\n",
              "  181.06007385253906,\n",
              "  184.76405334472656,\n",
              "  184.589111328125,\n",
              "  180.3972930908203,\n",
              "  185.90338134765625,\n",
              "  181.9956817626953,\n",
              "  180.45040893554688,\n",
              "  178.7338104248047,\n",
              "  181.68260192871094,\n",
              "  179.0504608154297,\n",
              "  179.2635955810547,\n",
              "  182.76123046875,\n",
              "  179.92979431152344,\n",
              "  180.00823974609375,\n",
              "  177.84390258789062,\n",
              "  180.36155700683594,\n",
              "  180.25775146484375,\n",
              "  178.210693359375,\n",
              "  178.02894592285156,\n",
              "  177.83401489257812,\n",
              "  177.81765747070312,\n",
              "  178.62574768066406,\n",
              "  179.02589416503906,\n",
              "  179.6551971435547,\n",
              "  179.85675048828125,\n",
              "  177.46372985839844,\n",
              "  177.1449432373047,\n",
              "  176.95274353027344,\n",
              "  178.09617614746094,\n",
              "  177.64193725585938,\n",
              "  178.82098388671875,\n",
              "  179.6619415283203,\n",
              "  176.1985626220703,\n",
              "  176.0906524658203,\n",
              "  177.8438262939453,\n",
              "  179.965576171875,\n",
              "  175.65719604492188,\n",
              "  178.34100341796875,\n",
              "  175.06593322753906,\n",
              "  177.19447326660156,\n",
              "  175.86758422851562,\n",
              "  177.93028259277344,\n",
              "  174.00119018554688,\n",
              "  174.41653442382812,\n",
              "  178.15399169921875,\n",
              "  175.88169860839844,\n",
              "  177.165771484375,\n",
              "  173.9898223876953,\n",
              "  174.5133514404297,\n",
              "  176.23269653320312,\n",
              "  172.93267822265625,\n",
              "  173.94943237304688,\n",
              "  174.587646484375,\n",
              "  174.7896270751953,\n",
              "  173.8900604248047,\n",
              "  174.72943115234375,\n",
              "  175.31346130371094,\n",
              "  174.6717071533203,\n",
              "  175.66848754882812,\n",
              "  174.99789428710938,\n",
              "  173.371337890625,\n",
              "  172.33213806152344,\n",
              "  171.4661407470703,\n",
              "  171.21128845214844,\n",
              "  172.56443786621094,\n",
              "  172.74774169921875,\n",
              "  173.29440307617188,\n",
              "  172.2671661376953,\n",
              "  173.55224609375,\n",
              "  171.8131561279297,\n",
              "  172.4127655029297,\n",
              "  172.06295776367188,\n",
              "  171.52032470703125,\n",
              "  172.45774841308594,\n",
              "  172.70530700683594,\n",
              "  173.18124389648438,\n",
              "  172.60340881347656,\n",
              "  171.67970275878906,\n",
              "  171.26123046875,\n",
              "  173.49513244628906,\n",
              "  169.32763671875,\n",
              "  173.46051025390625,\n",
              "  169.49124145507812,\n",
              "  171.5511932373047,\n",
              "  169.11830139160156,\n",
              "  169.46707153320312,\n",
              "  169.1416778564453,\n",
              "  168.9781951904297,\n",
              "  170.49656677246094,\n",
              "  171.20263671875,\n",
              "  172.14093017578125,\n",
              "  171.28985595703125,\n",
              "  169.1486053466797,\n",
              "  170.99742126464844,\n",
              "  169.18748474121094,\n",
              "  171.43304443359375,\n",
              "  172.15963745117188,\n",
              "  168.76622009277344,\n",
              "  167.52679443359375,\n",
              "  167.66880798339844,\n",
              "  167.75672912597656,\n",
              "  169.15708923339844,\n",
              "  171.55264282226562,\n",
              "  166.86318969726562,\n",
              "  168.33755493164062,\n",
              "  171.4987030029297,\n",
              "  170.66455078125,\n",
              "  166.77825927734375,\n",
              "  170.3978729248047,\n",
              "  167.38015747070312,\n",
              "  167.14439392089844,\n",
              "  166.636962890625,\n",
              "  166.19386291503906,\n",
              "  169.20033264160156,\n",
              "  169.6015625,\n",
              "  168.12063598632812,\n",
              "  165.55886840820312,\n",
              "  166.76849365234375,\n",
              "  166.97047424316406,\n",
              "  166.78575134277344,\n",
              "  165.83175659179688,\n",
              "  166.35043334960938,\n",
              "  166.79754638671875,\n",
              "  167.6422576904297,\n",
              "  168.00222778320312,\n",
              "  165.50413513183594,\n",
              "  172.2784881591797,\n",
              "  165.68922424316406,\n",
              "  166.93975830078125,\n",
              "  169.77569580078125,\n",
              "  168.10438537597656,\n",
              "  166.98785400390625,\n",
              "  166.9130096435547,\n",
              "  164.93092346191406],\n",
              " 'mse': [580.2256469726562,\n",
              "  577.931640625,\n",
              "  575.1408081054688,\n",
              "  571.7400512695312,\n",
              "  567.7205200195312,\n",
              "  563.1090698242188,\n",
              "  557.8209838867188,\n",
              "  551.9439697265625,\n",
              "  545.390869140625,\n",
              "  538.2705688476562,\n",
              "  530.605224609375,\n",
              "  522.1884155273438,\n",
              "  513.2766723632812,\n",
              "  504.0526428222656,\n",
              "  494.15875244140625,\n",
              "  483.9072265625,\n",
              "  473.17626953125,\n",
              "  462.17822265625,\n",
              "  451.0127258300781,\n",
              "  439.5052185058594,\n",
              "  427.8293762207031,\n",
              "  416.01739501953125,\n",
              "  404.32177734375,\n",
              "  392.4888610839844,\n",
              "  380.7012023925781,\n",
              "  368.91900634765625,\n",
              "  357.4859619140625,\n",
              "  346.0303649902344,\n",
              "  334.9601135253906,\n",
              "  324.2062683105469,\n",
              "  313.6064147949219,\n",
              "  303.56146240234375,\n",
              "  293.81170654296875,\n",
              "  284.54473876953125,\n",
              "  275.64666748046875,\n",
              "  267.1828308105469,\n",
              "  259.23846435546875,\n",
              "  251.76937866210938,\n",
              "  244.70188903808594,\n",
              "  238.18321228027344,\n",
              "  232.0939178466797,\n",
              "  226.5961456298828,\n",
              "  221.54019165039062,\n",
              "  216.73341369628906,\n",
              "  212.56153869628906,\n",
              "  208.78826904296875,\n",
              "  205.26614379882812,\n",
              "  202.24534606933594,\n",
              "  199.55543518066406,\n",
              "  197.1738739013672,\n",
              "  194.93202209472656,\n",
              "  193.1117706298828,\n",
              "  191.48263549804688,\n",
              "  189.9833526611328,\n",
              "  188.7863006591797,\n",
              "  187.64871215820312,\n",
              "  186.7283172607422,\n",
              "  185.86749267578125,\n",
              "  185.18067932128906,\n",
              "  184.5605010986328,\n",
              "  184.00244140625,\n",
              "  183.5216064453125,\n",
              "  183.1356964111328,\n",
              "  182.79261779785156,\n",
              "  182.45050048828125,\n",
              "  182.20028686523438,\n",
              "  181.9593505859375,\n",
              "  181.7471160888672,\n",
              "  181.549072265625,\n",
              "  181.3732452392578,\n",
              "  181.1882781982422,\n",
              "  181.0447540283203,\n",
              "  180.89712524414062,\n",
              "  180.74998474121094,\n",
              "  180.62461853027344,\n",
              "  180.50743103027344,\n",
              "  180.37081909179688,\n",
              "  180.2523193359375,\n",
              "  180.14735412597656,\n",
              "  180.0015106201172,\n",
              "  179.88890075683594,\n",
              "  179.76815795898438,\n",
              "  179.6439666748047,\n",
              "  179.53216552734375,\n",
              "  179.41050720214844,\n",
              "  179.29440307617188,\n",
              "  179.18679809570312,\n",
              "  179.04730224609375,\n",
              "  178.93142700195312,\n",
              "  178.8091278076172,\n",
              "  178.70220947265625,\n",
              "  178.56336975097656,\n",
              "  178.43289184570312,\n",
              "  178.30860900878906,\n",
              "  178.178955078125,\n",
              "  178.0457000732422,\n",
              "  177.912841796875,\n",
              "  177.7840576171875,\n",
              "  177.6509552001953,\n",
              "  177.5136260986328,\n",
              "  177.3794403076172,\n",
              "  177.253662109375,\n",
              "  177.1096649169922,\n",
              "  176.96505737304688,\n",
              "  176.83505249023438,\n",
              "  176.6910400390625,\n",
              "  176.55323791503906,\n",
              "  176.41513061523438,\n",
              "  176.27880859375,\n",
              "  176.13418579101562,\n",
              "  176.0042724609375,\n",
              "  175.85906982421875,\n",
              "  175.7180938720703,\n",
              "  175.57421875,\n",
              "  175.4383544921875,\n",
              "  175.29888916015625,\n",
              "  175.1782684326172,\n",
              "  175.02012634277344,\n",
              "  174.87818908691406,\n",
              "  174.74887084960938,\n",
              "  174.6133575439453,\n",
              "  174.46852111816406,\n",
              "  174.32492065429688,\n",
              "  174.20875549316406,\n",
              "  174.053955078125,\n",
              "  173.91343688964844,\n",
              "  173.7848663330078,\n",
              "  173.64569091796875,\n",
              "  173.51121520996094,\n",
              "  173.37754821777344,\n",
              "  173.2528839111328,\n",
              "  173.10980224609375,\n",
              "  172.986572265625,\n",
              "  172.8536834716797,\n",
              "  172.72401428222656,\n",
              "  172.59339904785156,\n",
              "  172.46421813964844,\n",
              "  172.34312438964844,\n",
              "  172.2218475341797,\n",
              "  172.09280395507812,\n",
              "  171.9624481201172,\n",
              "  171.86886596679688,\n",
              "  171.72100830078125,\n",
              "  171.59156799316406,\n",
              "  171.47731018066406,\n",
              "  171.37142944335938,\n",
              "  171.23138427734375,\n",
              "  171.12353515625,\n",
              "  170.9985809326172,\n",
              "  170.8970184326172,\n",
              "  170.7679443359375,\n",
              "  170.66795349121094,\n",
              "  170.56048583984375,\n",
              "  170.42852783203125,\n",
              "  170.3218994140625,\n",
              "  170.2152862548828,\n",
              "  170.1324462890625,\n",
              "  169.99412536621094,\n",
              "  169.8914031982422,\n",
              "  169.78558349609375,\n",
              "  169.7089080810547,\n",
              "  169.58168029785156,\n",
              "  169.48399353027344,\n",
              "  169.4213104248047,\n",
              "  169.2911834716797,\n",
              "  169.1846923828125,\n",
              "  169.09576416015625,\n",
              "  169.00262451171875,\n",
              "  168.8972625732422,\n",
              "  168.79803466796875,\n",
              "  168.70237731933594,\n",
              "  168.63380432128906,\n",
              "  168.52120971679688,\n",
              "  168.44822692871094,\n",
              "  168.35755920410156,\n",
              "  168.27207946777344,\n",
              "  168.1795196533203,\n",
              "  168.0996551513672,\n",
              "  168.0072784423828,\n",
              "  167.94125366210938,\n",
              "  167.84375,\n",
              "  167.78131103515625,\n",
              "  167.69613647460938,\n",
              "  167.60508728027344,\n",
              "  167.53775024414062,\n",
              "  167.4634552001953,\n",
              "  167.39120483398438,\n",
              "  167.3129425048828,\n",
              "  167.2535400390625,\n",
              "  167.1776885986328,\n",
              "  167.1110382080078,\n",
              "  167.03517150878906,\n",
              "  166.98068237304688,\n",
              "  166.9025421142578,\n",
              "  166.83551025390625,\n",
              "  166.76449584960938,\n",
              "  166.69711303710938,\n",
              "  166.63880920410156,\n",
              "  166.56446838378906,\n",
              "  166.50868225097656],\n",
              " 'val_loss': [692.63818359375,\n",
              "  689.8130493164062,\n",
              "  686.3480834960938,\n",
              "  682.1932983398438,\n",
              "  677.3828735351562,\n",
              "  671.862548828125,\n",
              "  665.6659545898438,\n",
              "  658.7643432617188,\n",
              "  651.1769409179688,\n",
              "  642.8912963867188,\n",
              "  633.84912109375,\n",
              "  624.341796875,\n",
              "  614.27490234375,\n",
              "  603.4349365234375,\n",
              "  592.1898803710938,\n",
              "  580.5028076171875,\n",
              "  568.4226684570312,\n",
              "  555.9535522460938,\n",
              "  543.09130859375,\n",
              "  529.9705200195312,\n",
              "  516.7898559570312,\n",
              "  503.544189453125,\n",
              "  490.0281982421875,\n",
              "  476.5656433105469,\n",
              "  463.10675048828125,\n",
              "  449.903076171875,\n",
              "  436.5909423828125,\n",
              "  423.65264892578125,\n",
              "  410.95501708984375,\n",
              "  398.428955078125,\n",
              "  386.4319763183594,\n",
              "  374.7320251464844,\n",
              "  363.4398193359375,\n",
              "  352.5014953613281,\n",
              "  342.14569091796875,\n",
              "  332.2601013183594,\n",
              "  322.7402038574219,\n",
              "  313.707763671875,\n",
              "  305.2919921875,\n",
              "  297.39190673828125,\n",
              "  290.09320068359375,\n",
              "  283.1083068847656,\n",
              "  276.54931640625,\n",
              "  270.7498474121094,\n",
              "  265.2696228027344,\n",
              "  260.1718444824219,\n",
              "  255.71267700195312,\n",
              "  251.5673828125,\n",
              "  247.79501342773438,\n",
              "  244.337890625,\n",
              "  241.3765106201172,\n",
              "  238.56463623046875,\n",
              "  236.00991821289062,\n",
              "  233.87550354003906,\n",
              "  231.87063598632812,\n",
              "  230.12939453125,\n",
              "  228.46749877929688,\n",
              "  227.1129150390625,\n",
              "  225.8167724609375,\n",
              "  224.58580017089844,\n",
              "  223.49942016601562,\n",
              "  222.61749267578125,\n",
              "  221.7610626220703,\n",
              "  221.00775146484375,\n",
              "  220.42828369140625,\n",
              "  219.82064819335938,\n",
              "  219.31399536132812,\n",
              "  218.858154296875,\n",
              "  218.43069458007812,\n",
              "  217.95486450195312,\n",
              "  217.68551635742188,\n",
              "  217.2727508544922,\n",
              "  216.94781494140625,\n",
              "  216.73171997070312,\n",
              "  216.50979614257812,\n",
              "  216.2354736328125,\n",
              "  216.08108520507812,\n",
              "  215.96408081054688,\n",
              "  215.66221618652344,\n",
              "  215.54257202148438,\n",
              "  215.36441040039062,\n",
              "  215.21170043945312,\n",
              "  215.08538818359375,\n",
              "  215.0078125,\n",
              "  214.84921264648438,\n",
              "  214.79498291015625,\n",
              "  214.61483764648438,\n",
              "  214.5152587890625,\n",
              "  214.4232177734375,\n",
              "  214.40625,\n",
              "  214.10269165039062,\n",
              "  213.96128845214844,\n",
              "  213.93121337890625,\n",
              "  213.8599853515625,\n",
              "  213.740234375,\n",
              "  213.60317993164062,\n",
              "  213.43490600585938,\n",
              "  213.30340576171875,\n",
              "  213.154541015625,\n",
              "  213.01638793945312,\n",
              "  213.00601196289062,\n",
              "  212.79981994628906,\n",
              "  212.65333557128906,\n",
              "  212.55209350585938,\n",
              "  212.39413452148438,\n",
              "  212.33334350585938,\n",
              "  212.14996337890625,\n",
              "  212.11575317382812,\n",
              "  212.022216796875,\n",
              "  211.93011474609375,\n",
              "  211.85440063476562,\n",
              "  211.6256103515625,\n",
              "  211.563720703125,\n",
              "  211.3651123046875,\n",
              "  211.21090698242188,\n",
              "  211.11904907226562,\n",
              "  210.89199829101562,\n",
              "  210.99658203125,\n",
              "  210.81576538085938,\n",
              "  210.79452514648438,\n",
              "  210.58432006835938,\n",
              "  210.41212463378906,\n",
              "  210.3232879638672,\n",
              "  210.34323120117188,\n",
              "  210.1514892578125,\n",
              "  210.00466918945312,\n",
              "  209.87149047851562,\n",
              "  209.75479125976562,\n",
              "  209.55780029296875,\n",
              "  209.5150146484375,\n",
              "  209.48138427734375,\n",
              "  209.34683227539062,\n",
              "  209.258544921875,\n",
              "  209.11898803710938,\n",
              "  208.97015380859375,\n",
              "  208.79660034179688,\n",
              "  208.69566345214844,\n",
              "  208.540283203125,\n",
              "  208.3978271484375,\n",
              "  208.28945922851562,\n",
              "  208.2685546875,\n",
              "  208.05120849609375,\n",
              "  208.01634216308594,\n",
              "  207.8922119140625,\n",
              "  207.70245361328125,\n",
              "  207.61837768554688,\n",
              "  207.5079345703125,\n",
              "  207.54660034179688,\n",
              "  207.37478637695312,\n",
              "  207.36395263671875,\n",
              "  207.14700317382812,\n",
              "  207.14051818847656,\n",
              "  206.94387817382812,\n",
              "  206.8878173828125,\n",
              "  206.9130859375,\n",
              "  206.7998046875,\n",
              "  206.88308715820312,\n",
              "  206.59884643554688,\n",
              "  206.41964721679688,\n",
              "  206.352783203125,\n",
              "  206.10006713867188,\n",
              "  206.2352752685547,\n",
              "  206.14138793945312,\n",
              "  205.81480407714844,\n",
              "  205.93511962890625,\n",
              "  205.9384765625,\n",
              "  205.7470703125,\n",
              "  205.87158203125,\n",
              "  205.7525634765625,\n",
              "  205.5155029296875,\n",
              "  205.41119384765625,\n",
              "  205.37074279785156,\n",
              "  205.11074829101562,\n",
              "  204.90713500976562,\n",
              "  204.9714813232422,\n",
              "  204.83856201171875,\n",
              "  204.80609130859375,\n",
              "  204.78463745117188,\n",
              "  204.75408935546875,\n",
              "  204.75851440429688,\n",
              "  204.68167114257812,\n",
              "  204.48939514160156,\n",
              "  204.34695434570312,\n",
              "  204.35955810546875,\n",
              "  204.50430297851562,\n",
              "  204.41751098632812,\n",
              "  204.2978515625,\n",
              "  204.26040649414062,\n",
              "  204.25579833984375,\n",
              "  204.15512084960938,\n",
              "  204.02426147460938,\n",
              "  204.00050354003906,\n",
              "  204.18795776367188,\n",
              "  203.82196044921875,\n",
              "  203.83978271484375,\n",
              "  203.7975311279297,\n",
              "  203.45712280273438,\n",
              "  203.4931640625,\n",
              "  203.37167358398438,\n",
              "  203.31817626953125],\n",
              " 'val_mse': [608.4952392578125,\n",
              "  605.8662719726562,\n",
              "  602.6433715820312,\n",
              "  598.772705078125,\n",
              "  594.2852172851562,\n",
              "  589.1365966796875,\n",
              "  583.3594970703125,\n",
              "  576.9271240234375,\n",
              "  569.8595581054688,\n",
              "  562.1455688476562,\n",
              "  553.73193359375,\n",
              "  544.8935546875,\n",
              "  535.5427856445312,\n",
              "  525.4833984375,\n",
              "  515.0592041015625,\n",
              "  504.2364807128906,\n",
              "  493.0639953613281,\n",
              "  481.5470275878906,\n",
              "  469.68218994140625,\n",
              "  457.599609375,\n",
              "  445.4822998046875,\n",
              "  433.327880859375,\n",
              "  420.9497985839844,\n",
              "  408.6471252441406,\n",
              "  396.3770751953125,\n",
              "  384.3694763183594,\n",
              "  372.2939758300781,\n",
              "  360.59295654296875,\n",
              "  349.1470642089844,\n",
              "  337.89276123046875,\n",
              "  327.1533508300781,\n",
              "  316.7206726074219,\n",
              "  306.69390869140625,\n",
              "  297.0255432128906,\n",
              "  287.9173889160156,\n",
              "  279.26806640625,\n",
              "  270.9871826171875,\n",
              "  263.1799011230469,\n",
              "  255.95242309570312,\n",
              "  249.2169189453125,\n",
              "  243.04122924804688,\n",
              "  237.1810302734375,\n",
              "  231.72715759277344,\n",
              "  226.95126342773438,\n",
              "  222.48374938964844,\n",
              "  218.3739776611328,\n",
              "  214.8202362060547,\n",
              "  211.55819702148438,\n",
              "  208.62747192382812,\n",
              "  205.98052978515625,\n",
              "  203.74285888671875,\n",
              "  201.65203857421875,\n",
              "  199.7827606201172,\n",
              "  198.2443389892578,\n",
              "  196.82379150390625,\n",
              "  195.6087646484375,\n",
              "  194.47215270996094,\n",
              "  193.5546875,\n",
              "  192.69664001464844,\n",
              "  191.8977813720703,\n",
              "  191.2034912109375,\n",
              "  190.6451416015625,\n",
              "  190.1148681640625,\n",
              "  189.64947509765625,\n",
              "  189.2876434326172,\n",
              "  188.9176483154297,\n",
              "  188.60577392578125,\n",
              "  188.32647705078125,\n",
              "  188.0623779296875,\n",
              "  187.78411865234375,\n",
              "  187.6020965576172,\n",
              "  187.35870361328125,\n",
              "  187.1536407470703,\n",
              "  186.99761962890625,\n",
              "  186.83824157714844,\n",
              "  186.65826416015625,\n",
              "  186.52516174316406,\n",
              "  186.4075469970703,\n",
              "  186.2205810546875,\n",
              "  186.0991668701172,\n",
              "  185.95236206054688,\n",
              "  185.8192596435547,\n",
              "  185.6966094970703,\n",
              "  185.58639526367188,\n",
              "  185.4515380859375,\n",
              "  185.3454132080078,\n",
              "  185.19847106933594,\n",
              "  185.08360290527344,\n",
              "  184.9581298828125,\n",
              "  184.8679656982422,\n",
              "  184.68154907226562,\n",
              "  184.54547119140625,\n",
              "  184.4424285888672,\n",
              "  184.32481384277344,\n",
              "  184.1892852783203,\n",
              "  184.0538787841797,\n",
              "  183.90570068359375,\n",
              "  183.7691650390625,\n",
              "  183.6178741455078,\n",
              "  183.4738006591797,\n",
              "  183.37136840820312,\n",
              "  183.20567321777344,\n",
              "  183.0552978515625,\n",
              "  182.92654418945312,\n",
              "  182.7705841064453,\n",
              "  182.64675903320312,\n",
              "  182.48739624023438,\n",
              "  182.3698272705078,\n",
              "  182.2350311279297,\n",
              "  182.1044921875,\n",
              "  181.9768524169922,\n",
              "  181.7989959716797,\n",
              "  181.67413330078125,\n",
              "  181.505859375,\n",
              "  181.3534393310547,\n",
              "  181.2148895263672,\n",
              "  181.0386962890625,\n",
              "  180.96852111816406,\n",
              "  180.80551147460938,\n",
              "  180.69065856933594,\n",
              "  180.51803588867188,\n",
              "  180.36427307128906,\n",
              "  180.23663330078125,\n",
              "  180.136962890625,\n",
              "  179.9706268310547,\n",
              "  179.82505798339844,\n",
              "  179.67369079589844,\n",
              "  179.53343200683594,\n",
              "  179.37429809570312,\n",
              "  179.25621032714844,\n",
              "  179.14202880859375,\n",
              "  179.0001678466797,\n",
              "  178.8751678466797,\n",
              "  178.73138427734375,\n",
              "  178.5843505859375,\n",
              "  178.4306640625,\n",
              "  178.3017120361328,\n",
              "  178.1551971435547,\n",
              "  178.0162811279297,\n",
              "  177.88385009765625,\n",
              "  177.77830505371094,\n",
              "  177.61485290527344,\n",
              "  177.51097106933594,\n",
              "  177.3769989013672,\n",
              "  177.22769165039062,\n",
              "  177.1077423095703,\n",
              "  176.9816131591797,\n",
              "  176.89617919921875,\n",
              "  176.7555389404297,\n",
              "  176.6629180908203,\n",
              "  176.5076141357422,\n",
              "  176.41249084472656,\n",
              "  176.26715087890625,\n",
              "  176.16197204589844,\n",
              "  176.0830841064453,\n",
              "  175.9558868408203,\n",
              "  175.899658203125,\n",
              "  175.7336883544922,\n",
              "  175.5951690673828,\n",
              "  175.4916534423828,\n",
              "  175.3311004638672,\n",
              "  175.29205322265625,\n",
              "  175.1855010986328,\n",
              "  175.0086212158203,\n",
              "  174.9599609375,\n",
              "  174.87750244140625,\n",
              "  174.74472045898438,\n",
              "  174.70907592773438,\n",
              "  174.59718322753906,\n",
              "  174.4490509033203,\n",
              "  174.3493194580078,\n",
              "  174.2606658935547,\n",
              "  174.114990234375,\n",
              "  173.9827423095703,\n",
              "  173.9326171875,\n",
              "  173.8187255859375,\n",
              "  173.73851013183594,\n",
              "  173.66188049316406,\n",
              "  173.5895538330078,\n",
              "  173.52389526367188,\n",
              "  173.4374542236328,\n",
              "  173.3076934814453,\n",
              "  173.2024383544922,\n",
              "  173.1484832763672,\n",
              "  173.1292724609375,\n",
              "  173.0448455810547,\n",
              "  172.94659423828125,\n",
              "  172.8767852783203,\n",
              "  172.81985473632812,\n",
              "  172.7274932861328,\n",
              "  172.63168334960938,\n",
              "  172.56228637695312,\n",
              "  172.56887817382812,\n",
              "  172.39834594726562,\n",
              "  172.35064697265625,\n",
              "  172.282470703125,\n",
              "  172.1349639892578,\n",
              "  172.09083557128906,\n",
              "  172.0068359375,\n",
              "  171.9373779296875]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOkGmAYCRd9",
        "colab_type": "code",
        "outputId": "9c9d6052-0bc4-4e02-c455-bad8506f0738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.plot(hist['loss'], label='Training Loss')\n",
        "plt.plot(hist['val_loss'], label='Validation Loss')\n",
        "# plt.xticks(np.arange(0, 5), ('1','2','3','4','5'))\n",
        "plt.xlabel('# of epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend();"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXwV1dnA8d9zb/Z9BQIJhCUQ9gTCqiiIK6C44VKtIL5utVr1bavt28UuttraqrTVVmvdakHrgqDiBrJUKvu+BwiQAIEQCAnZ7z3vHzOJIWYn994sz/fzuZ87c+bM3IdJuE/OOTNnxBiDUkopBeDwdQBKKaXaDk0KSimlqmlSUEopVU2TglJKqWqaFJRSSlXz83UA5yIuLs4kJyf7OgyllGpX1q1bl2eMia9rW7tOCsnJyaxdu9bXYSilVLsiIgfq26bdR0oppappUlBKKVXNY0lBRAaIyMYar9Mi8qCIxIjIZyKyx36PtuuLiMwRkUwR2SwiIzwVm1JKqbp5bEzBGLMLSAMQESeQA7wHPAosNsY8ISKP2uuPAFcAKfZrDPC8/a6U8rGKigqys7MpLS31dSiqGYKCgkhMTMTf37/J+3hroHkysNcYc0BEpgMT7fJXgaVYSWE68JqxJmP6SkSiRCTBGHPESzEqpeqRnZ1NeHg4ycnJiIivw1FNYIzhxIkTZGdn07t37ybv560xhZuAufZy1xpf9EeBrvZyD+BQjX2y7bKziMhdIrJWRNYeP37cU/EqpWooLS0lNjZWE0I7IiLExsY2u3Xn8aQgIgHAVcC/a2+zWwXNmqbVGPOCMSbDGJMRH1/nZbZKKQ/QhND+tORn5o2WwhXAemNMrr2eKyIJAPb7Mbs8B0iqsV+iXdb68vbA4l9BZblHDq+UUu2VN5LCzXzddQSwAJhpL88E3q9Rfpt9FdJYoMBj4wm7PoIVT8GLF8GxnR75CKVU6zlx4gRpaWmkpaXRrVs3evToUb1eXt7wH3dr167lgQceaPQzxo8f3yqxLl26lGnTprXKsXzBowPNIhIKXALcXaP4CeAtEbkDOADcYJd/BEwBMoFi4HaPBXbe9yA2BRY+AC9dAjNehn4Xe+zjlFLnJjY2lo0bNwLw2GOPERYWxve///3q7ZWVlfj51f11lpGRQUZGRqOfsXLlytYJtp3zaEvBGHPGGBNrjCmoUXbCGDPZGJNijLnYGJNvlxtjzH3GmL7GmKHGGM/OX5E6Be5aClG94I0bYPv7je2hlGpDZs2axT333MOYMWP44Q9/yOrVqxk3bhzp6emMHz+eXbt2AWf/5f7YY48xe/ZsJk6cSJ8+fZgzZ0718cLCwqrrT5w4keuvv57U1FRuueUWqp5Q+dFHH5GamsrIkSN54IEHmtUimDt3LkOHDmXIkCE88sgjALhcLmbNmsWQIUMYOnQoTz/9NABz5sxh0KBBDBs2jJtuuuncT1YztOu5j85ZZCLMXgT/vA7eng03vG4lC6VUvX6xcBvbD59u1WMO6h7Bz68c3Oz9srOzWblyJU6nk9OnT7NixQr8/Pz4/PPP+fGPf8w777zzjX127tzJF198QWFhIQMGDODee+/9xnX8GzZsYNu2bXTv3p3zzjuPL7/8koyMDO6++26WL19O7969ufnmm5sc5+HDh3nkkUdYt24d0dHRXHrppcyfP5+kpCRycnLYunUrAKdOnQLgiSeeYP/+/QQGBlaXeYtOcxEYDre8Dd2GWYkhZ72vI1JKNdGMGTNwOp0AFBQUMGPGDIYMGcJDDz3Etm3b6txn6tSpBAYGEhcXR5cuXcjNzf1GndGjR5OYmIjD4SAtLY2srCx27txJnz59qq/5b05SWLNmDRMnTiQ+Ph4/Pz9uueUWli9fTp8+fdi3bx/3338/H3/8MREREQAMGzaMW265hX/+85/1dot5SuduKVQJioBvvQkvToa5N8PdyyC8m6+jUqpNaslf9J4SGhpavfzTn/6USZMm8d5775GVlcXEiRPr3CcwMLB62el0UllZ2aI6rSE6OppNmzbxySef8Ne//pW33nqLf/zjH3z44YcsX76chQsX8vjjj7NlyxavJQdtKVQJ6wLfmgelBfDuneB2+ToipVQzFBQU0KOHdb/rK6+80urHHzBgAPv27SMrKwuAN998s8n7jh49mmXLlpGXl4fL5WLu3LlceOGF5OXl4Xa7ue666/j1r3/N+vXrcbvdHDp0iEmTJvHkk09SUFBAUVFRq/976qNJoaaug2HK72D/cvjP076ORinVDD/84Q/50Y9+RHp6ukf+sg8ODua5557j8ssvZ+TIkYSHhxMZGVln3cWLF5OYmFj9ysrK4oknnmDSpEkMHz6ckSNHMn36dHJycpg4cSJpaWnceuut/Pa3v8XlcnHrrbcydOhQ0tPTeeCBB4iKimr1f099pGpUvT3KyMgwrf6QHWPg7dthxwdWN1LXttNUVspXduzYwcCBA30dhs8VFRURFhaGMYb77ruPlJQUHnroIV+H1aC6fnYiss4YU+d1utpSqE0EpvwBgiJh/nfA5Zm+RKVU+/Piiy+SlpbG4MGDKSgo4O677258p3ZGk0JdQmNhyu/hyEZY83dfR6OUaiMeeughNm7cyPbt23njjTcICQnxdUitTpNCfQZfA30vgi9+A0U6G6tSqnPQpFAfEbjid1BRDIt/4etolFLKKzQpNCQuBcbcDRvfgNztvo5GKaU8TpNCYyb8LwSEw+Jf+joSpZTyOE0KjQmJgfO/B7sXwcFVvo5GqU5p0qRJfPLJJ2eVPfPMM9x777317jNx4kSqLlmfMmVKnXMIPfbYYzz11FMNfvb8+fPZvv3rnoKf/exnfP75580Jv05tdYptTQpNMeZeCI2HZU/6OhKlOqWbb76ZefPmnVU2b968Js8/9NFHH7X4BrDaSeGXv/wlF1/ccafa16TQFAEhMP5+2LsYsj07o7dS6puuv/56Pvzww+oH6mRlZXH48GEmTJjAvffeS0ZGBoMHD+bnP/95nfsnJyeTl5cHwOOPP07//v05//zzq6fXBusehFGjRjF8+HCuu+46iouLWblyJQsWLOAHP/gBaWlp7N27l1mzZvH2228D1p3L6enpDB06lNmzZ1NWVlb9eT//+c8ZMWIEQ4cOZefOpj/My9dTbOuEeE2VcQf85xlY9ju45S1fR6OU7yx6FI5uad1jdhsKVzxR7+aYmBhGjx7NokWLmD59OvPmzeOGG25ARHj88ceJiYnB5XIxefJkNm/ezLBhw+o8zrp165g3bx4bN26ksrKSESNGMHLkSACuvfZa7rzzTgB+8pOf8NJLL3H//fdz1VVXMW3aNK6//vqzjlVaWsqsWbNYvHgx/fv357bbbuP555/nwQcfBCAuLo7169fz3HPP8dRTT/H3vzd+z1NbmGJbWwpNFRgGY+6BPZ/A8d2+jkapTqdmF1LNrqO33nqLESNGkJ6ezrZt287q6qltxYoVXHPNNYSEhBAREcFVV11VvW3r1q1MmDCBoUOH8sYbb9Q79XaVXbt20bt3b/r37w/AzJkzWb58efX2a6+9FoCRI0dWT6LXmLYwxba2FJojYzas+AOseh6m6YR5qpNq4C96T5o+fToPPfQQ69evp7i4mJEjR7J//36eeuop1qxZQ3R0NLNmzaK0tLRFx581axbz589n+PDhvPLKKyxduvSc4q2afrs1pt725hTb2lJojrB4GHYDbJwLxfm+jkapTiUsLIxJkyYxe/bs6lbC6dOnCQ0NJTIyktzcXBYtWtTgMS644ALmz59PSUkJhYWFLFy4sHpbYWEhCQkJVFRU8MYbb1SXh4eHU1hY+I1jDRgwgKysLDIzMwF4/fXXufDCC8/p39gWptjWlkJzjf0ObHgd1r0CEx72dTRKdSo333wz11xzTXU30vDhw0lPTyc1NZWkpCTOO++8BvcfMWIEN954I8OHD6dLly6MGjWqetuvfvUrxowZQ3x8PGPGjKlOBDfddBN33nknc+bMqR5gBggKCuLll19mxowZVFZWMmrUKO65555m/Xuqptiu8u9//7t6im1jDFOnTmX69Ols2rSJ22+/HbfbDXDWFNsFBQUYY1ptim2dOrslXptujSs8uBmc/o3XV6qd06mz2y+dOtsbxt4HhYdh23xfR6KUUq1Kk0JL9LsYYlPgq+d8HYlSSrUqTQot4XDA6Dvh8Ho4stnX0SjlFe25q7mzasnPTJNCSw2dAc5Aa9BZqQ4uKCiIEydOaGJoR4wxnDhxgqCgoGbtp1cftVRIDAy6Cja/CZf8EvyDfR2RUh6TmJhIdnY2x4/rA6fak6CgoLOubmoKTQrnYsRtsOXfsGOhdf+CUh2Uv78/vXv39nUYygu0++hc9DofonvD+td8HYlSSrUKTQrnwuGAEd+GrBVwYq+vo1FKqXPm0aQgIlEi8raI7BSRHSIyTkRiROQzEdljv0fbdUVE5ohIpohsFpERnoyt1Qz/FohDB5yVUh2Cp1sKzwIfG2NSgeHADuBRYLExJgVYbK8DXAGk2K+7gOc9HFvriEiAlMtg47/AdW6TXimllK95LCmISCRwAfASgDGm3BhzCpgOvGpXexW42l6eDrxmLF8BUSKS4Kn4WlXazVCUC/uX+ToSpZQ6J55sKfQGjgMvi8gGEfm7iIQCXY0xR+w6R4Gu9nIP4FCN/bPtsrOIyF0islZE1raZy+NSLoPASOtKJKWUasc8mRT8gBHA88aYdOAMX3cVAWCsO2GadTeMMeYFY0yGMSYjPj6+1YI9J/5BMOhK69LU8mJfR6OUUi3myaSQDWQbY1bZ629jJYncqm4h+/2YvT0HSKqxf6Jd1j4MuxHKi2B3w/O5K6VUW+axpGCMOQocEpEBdtFkYDuwAJhpl80E3reXFwC32VchjQUKanQztX29zofw7rBZu5CUUu2Xp+9ovh94Q0QCgH3A7ViJ6C0RuQM4AFTdCvwRMAXIBIrtuu2HwwFDr4OvnoczJyA01tcRKaVUs3k0KRhjNgJ1Pchhch11DXCfJ+PxuKE3wMo/wfb3YNT/+DoapZRqtk55R/Oe3EIeW7CNCpcbYwyFpRWtc+BuQyF+oHYhKaXarU45Id6KPXm8sjKLPccKqXAZNh06xaLvTaBPfNi5HVgEhl4PS34Fpw5BVFLj+yilVBvSKVsKs8/vze+uH8aqffnszi1EBP68JLN1Dj74Gut9x4LWOZ5SSnlRp0wKADdkJPHpQxew9PsTuXVML+ZvzGF/3plzP3BsX6sbSZ/frJRqhzptUgDoEx9GVEgAd13YhwA/B1f+6T/MfmUNp4rLz+3Ag66G7NVQkN06gSqllJd06qRQpUt4EK/ePpqr07uzfPdxfrFw+7kdsKoLafv7DddTSqk2RpOCbUyfWH599VC+M6kf723IYfGO3JYfTLuQlFLtlCaFWr47qR/9uoTx+092ndtDyrULSSnVDmlSqCXAz8Hs83qz82ghGw6davmBqruQ9CokpVT7oUmhDleldSckwMncVQdbfpDYvtB1KGzXLiSlVPuhSaEOYYF+TE/rzsLNh1m8I5fySnfLDjR4OhxaBafbz7x+SqnOTZNCPe44vzehAX7c8epaHpi7oWUHSb3Set/1UesFppRSHqRJoR79uoTz3x9N5rZxvfh0+1GOFZY2/yDxAyCmL+z8sPUDVEopD9Ck0IAAPwe3jeuF28CHm1vQBSQCqVNh/3IoLWj9AJVSqpVpUmhEvy7hDEyIYMGmwy07QOpUcFdA5uetG5hSSnmAJoUmuGp4dzYcPMWP39vC0l3HGt+hpsRREBqvXUhKqXZBk0ITXDeiB8OTopi/IYcfvL25eTe1OZww4ArY/SlUlnkuSKWUagWaFJqgS0QQ7993Hr+4ajDHC8vYlVvYvAOkToPyQsha4ZkAlVKqlWhSaIYJKfEArNid17wde18I/qHahaSUavM0KTRDt8ggUrqEsXzP8ebt6B8E/SbDrkXgbuGNcEop5QWaFJrp/JQ4Vu/Pp7TC1bwdU6dB4RE43MIb4ZRSygs0KTTTBSnxlFW6m38VUv9LQZyw8wPPBKaUUq1Ak0Izje8XS0qXMH4yf1vz7nIOjobk83RcQSnVpmlSaKZAPyd//tYICksr+O6/NlBS3oxupNRpkLcL8jI9F6BSSp0DTQotMKBbOL+7fhhrs/KZ+Y/VnCmrbOKOU6z3XdpaUEq1TZoUWmh6Wg+euSmd1Vn5zF3dxOcuRCVBwnDtQlJKtVmaFM7BVcO70yc+lC8zm3HfQuo0OLQaCs/hGdBKKeUhmhTO0fi+sazen0+Fq4n3HwyYAhjYvcijcSmlVEt4NCmISJaIbBGRjSKy1i6LEZHPRGSP/R5tl4uIzBGRTBHZLCIjPBlbaxnfN44z5S42ZzdxauyugyGqF+zUB+8opdoeb7QUJhlj0owxGfb6o8BiY0wKsNheB7gCSLFfdwHPeyG2cza2TywA/93bxC4kEasLad9SKGvmHEpKKeVhvug+mg68ai+/Clxdo/w1Y/kKiBKRBB/E1ywxoQGkdgtn5d4TTd8pdQq4ymDvEs8FppRSLeDppGCAT0VknYjcZZd1NcZUPcbsKNDVXu4BHKqxb7ZddhYRuUtE1orI2uPHmzkHkYdc2D+e1fvzOXyqpGk7JI2FoChrLiSllGpDPJ0UzjfGjMDqGrpPRC6oudFYDyZoxsMJwBjzgjEmwxiTER8f34qhttytY3thgL+v2N+0HZx+0P8y2P0JuJp4j4NSSnmBR5OCMSbHfj8GvAeMBnKruoXs96pJhHKApBq7J9plbV5STAjTh3dn7uqD5J8pb9pOA6ZAST5kr/ZscEop1QweSwoiEioi4VXLwKXAVmABMNOuNhN4315eANxmX4U0Fiio0c3U5t07sS+llS7ufG0t2SeLG9+h32RwBsAuvQpJKdV2eLKl0BX4j4hsAlYDHxpjPgaeAC4RkT3AxfY6wEfAPiATeBH4jgdja3UpXcOZc1M6u44Wcu1zKymvbOS+hcBwSJ6g4wpKqTbFz1MHNsbsA4bXUX4CmFxHuQHu81Q83nDl8O74Ox3c8891rM3KZ3y/uIZ3GHAFfPR9yNsDcSneCVIppRqgdzS3sgv6xxHg52DxziY8b2HAFda7diEppdoITQqtLCTAj/F9Y1nSlKQQmQjdhmkXklKqzdCk4AGTU7uwP+8Me48XNV55wBQ4tArONGNSPaWU8hBNCh4wKbULAEt2NLELybhhz6cejkoppRqnScEDEqNDSO0WzuKdTZgeO2E4hHfXcQWlVJugScFDLkrtwpqskxSUVDRcUcRqLWQugYpmPPNZKaU8QJOCh0we2BWX27B8dxPmZxowBSrOQNYKzwemlFIN0KTgIWlJUcSEBjTtKqTeEyAgTLuQlFI+p0nBQ5wOYeKAeJbsPMap4kbmQ/ILhL4XWZemmmbND6iUUq1Kk4IH3Tq2FyXlLma+vIaiskZmQx0wBQqPwJGN3glOKaXqoEnBg0b0jObP30pna04Bf1q8p+HKKZeCOPRGNqWUT2lS8LBLB3cjPSmK9QdPNlwxNNZ6+I6OKyilfEiTghcM7h7B9sOncbsbGS9InQJHt8Cpg94JTCmlamkwKYjIrTWWz6u17bueCqqjGdw9kjPlLg7kN/KchQFTrPddH3s+KKWUqkNjLYWHayz/qda22a0cS4c1qHsEANsOFzRcMbYvxPXXLiSllM80lhSknuW61lU9+ncNx98pbDt8uvHKA66ArP9AaSMJRCmlPKCxpGDqWa5rXdUjwM9BSpfwJiaFKeCugMzFng9MKaVqaSwppIrIZhHZUmO5an2AF+LrMKzB5gJMYzenJY6CkFjtQlJK+URjj+Mc6JUoOoGhiZH8e102u3OLGNAtvP6KDif0vwJ2LoTKcvAL8F6QSqlOr8GWgjHmQM0XUASMAOLsddVE04Z1JyTAyXNLMxuvPPBKa0xBJ8hTSnlZY5ekfiAiQ+zlBGAr1lVHr4vIg16Ir8OICQ3g2+N6sXDT4cafyNZnojVB3o4F3ghNKaWqNTam0NsYs9Vevh34zBhzJTAGvSS12e6c0IdAPyd/WdJIa8E/yJr2YueH4HZ5JzillKLxpFDzCTGTgY8AjDGFgNtTQXVUcWGB3Dq2J/M35pCVd6bhygOvhDPHrec3K6WUlzSWFA6JyP0icg3WWMLHACISDPh7OriO6M4L+uDvdPCXLxppLaRcAs5A2LHQO4EppRSNJ4U7gMHALOBGY8wpu3ws8LIH4+qwuoQH8a0xPXl3Qw65pxt4/GZguPWMhR0L9RkLSimvaezqo2PGmHuMMdONMZ/WKP/CGPOU58PrmK4fmYjLbVi5N6/hioOugoJDcHiDdwJTSnV6Dd6nICINXv5ijLmqdcPpHFK7RRAR5Meqfflck55Yf8X+l4M4rdZCjxHeC1Ap1Wk1dvPaOOAQMBdYhc531CqcDmF07xhW7c9vuGJIjPX85h0LYPLPQPT0K6U8q7ExhW7Aj4EhwLPAJUCeMWaZMWaZp4PryEb3jmF/3hmONTSuANZVSCcy4fgu7wSmlOrUGhtTcBljPjbGzMQaXM4EljbnWQoi4hSRDSLygb3eW0RWiUimiLwpIgF2eaC9nmlvT27xv6odGNM7FqDx1kLqNED0KiSllFc0+uQ1+8v6WuCfwH3AHOC9ZnzG94AdNdafBJ42xvQDTmJd4YT9ftIuf9qu12EN7h5BWKAf/9nTyGBzeDdIGgM73vdOYEqpTq2xaS5eA/6LdY/CL4wxo4wxvzLG5DTl4CKSCEwF/m6vC3AR8LZd5VXgant5ur2OvX2yXb9D8nM6mDYsgX+vO9T4VUgDr7Qe05m/3zvBKaU6rcZaCrcCKVh/7a8UkdP2q1BEmvBwAJ4BfsjXdz/HAqeMMZX2ejbQw17ugTWojb29wK5/FhG5S0TWisja48ePNyGEtuun0waRHBfK9+ZtpKC4ov6KA6dZ79u1taCU8qzGxhQcxphw+xVR4xVujIloaF8RmQYcM8asa82AjTEvGGMyjDEZ8fHxrXlorwsN9OOJa4dxvLCM5XsaSHDRydBjJGx712uxKaU6p0bHFM7BecBVIpIFzMPqNnoWiBKRqkthE4GqrqgcIAnA3h4JnPBgfG1Ces8ogvwdbDh4quGKQ66DI5sgrwlTbyulVAt5LCkYY35kjEk0xiQDNwFLjDG3AF8A19vVZgJVfSIL7HXs7UtMo48pa//8nQ6G9Yhi/cGTDVccfA0gsPUdr8SllOqcPNlSqM8jwMMikok1ZvCSXf4SEGuXPww86oPYfCK9VxTbDhdQWtHANNkR3aHXebD1bZ0LSSnlMV5JCsaYpcaYafbyPmPMaGNMP2PMDGNMmV1eaq/3s7fv80ZsbcGIntFUuAzbDhc0XHHItZC3G3K3eScwpVSn44uWgqplRM9oANYfaGRcYdB0ay4k7UJSSnmIJoU2ID48kKSYYD7YcoTjhWX1VwyNsx7VufUd7UJSSnmEJoU24jsT+7H9cAGT/7CUgyeK66845Do4dQByWvVKX6WUAjQptBk3j+7Je985j9OllSzemVt/xYHTrCeybX7Le8EppToNTQptyJAekXSLCGr4noWgSBhwhXUVkquBu6CVUqoFNCm0Mek9o9h4qJEB5+E3Q/EJyPzcO0EppToNTQptTHrPKA7mF5NX1MCAc7/JEBIHm+Z6LzClVKegSaGNSUuyLk/d2FAXktMfhs6AXYugpJE7oZVSqhk0KbQxQ3tE4nRIE7qQbgJXOWxrzqMtlFKqYZoU2pjgACcDE8IbnwspYTjED4RN87wTmFKqU9Ck0AaN7xvHmqx8CkoauLpIxGotHFoFJ/Z6LzilVIemSaENunxINypchsU7GrhfAWDYDSAO2Pgv7wSmlOrwNCm0QWmJUSREBrFo69GGK0Z0h34Xw4Z/6j0LSqlWoUmhDXI4hMuHdGPZ7uMUlVU2XDljNhQdhd0feyc4pVSHpkmhjZoyNIHySjfvb8xpuGK/SyCiB6z9h3cCU0p1aJoU2qiMXtGMSo7m6c/2NNxacPrBiNtg7xLI3++9AJVSHZImhTZKRPjJ1EHkFZXx3BeNPJd5xG3WcxbWv+qd4JRSHZYmhTZseFIU04Yl8PpXB6hwueuvGNEd+l9uDThXlnsvQKVUh6NJoY2bOjSBwtLKxu9wzrgdzhyHnR94JzClVIekSaGNG98vDqdDWLrrWMMV+14EUb1g9YveCUwp1SFpUmjjIoP9GdkzmmW7jzdc0eGEMXfDwZVweIN3glNKdTiaFNqBCwfEszXnNMcKSxuumH4rBITBf5/zTmBKqQ5Hk0I7cGH/eACW7myktRAUCenfhm3vwukjXohMKdXRaFJoBwZ3jyA5NoR31mc3XnnM3eB2wRodW1BKNZ8mhXZARLh+ZCKr9udz8ERxw5VjekPqVOsO5/JG6iqlVC2aFNqJa0ckIgJvN6W1MPY71hPZNuuzFpRSzaNJoZ3oHhXM+f3ieHvtoYZvZAPoNR66p8OXz+rsqUqpZtGk0I7cNi6ZwwWlfLD5cMMVReDCR+BkFmx+0yuxKaU6Bo8lBREJEpHVIrJJRLaJyC/s8t4iskpEMkXkTREJsMsD7fVMe3uyp2JrryandqF/1zCeX7oXt9s0XLn/5dYjO5f/XlsLSqkm82RLoQy4yBgzHEgDLheRscCTwNPGmH7ASeAOu/4dwEm7/Gm7nqrB4RDundiX3blFLN7ZyB3OIjDxR9paUEo1i8eSgrEU2av+9ssAFwFv2+WvAlfby9Ptdeztk0VEPBVfe3XlsO4kRgfz3NJMjGlKayFNWwtKqSbz6JiCiDhFZCNwDPgM2AucMsZUPSAgG+hhL/cADgHY2wuA2DqOeZeIrBWRtcePN3IzVwfk53Rw9wV92HDwFF/ty2+4cs3Wwia9Ekkp1TiPJgVjjMsYkwYkAqOB1FY45gvGmAxjTEZ8fPw5x9gezchIIi4sgOeWNvKcBYD+l1lXIi39rd63oJRqlFeuPjLGnAK+AMYBUSLiZ29KBKqeN5kDJAHY2yOBE96Ir70J8ndy27hkVuzJ42hBI/MhicBlv4HTObDyT94JUCnVbnny6qN4EYmyl4OBS4AdWMnhetBnBQ0AABqTSURBVLvaTOB9e3mBvY69fYlptNO887p8SDcAljQ24AzWfQuDroYvn4GCRp75rJTq1DzZUkgAvhCRzcAa4DNjzAfAI8DDIpKJNWbwkl3/JSDWLn8YeNSDsbV7KV3CSIoJZvGO3KbtcMkvrDmRFv/Ss4Eppdo1v8artIwxZjOQXkf5PqzxhdrlpcAMT8XT0YgIk1O7Mnf1QUrKXQQHOBveIToZxt0H//kjjL4TEjO8EqdSqn3RO5rbsckDu1BW6eY/mXlN22HCwxDWFRb90Go1KKVULZoU2rExvWOJCwvgFwu3kXOqpPEdAsPh0l9DzjprFlWllKpFk0I7FuDn4OVZoykoqeCWF7+iuLyy8Z2GzoA+E62xBX0Qj1KqFk0K7dzQxEhe+HYGWSeK+euyfY3vIAJT/wjuSnjvbnA3MuOqUqpT0aTQAYzrG8u0YQm8sHwvRwqa0I0U2xcufwL2L4OVz3o+QKVUu6FJoYN45PJU3AbmLN7TtB1G3Gbdu7Dk15C9zrPBKaXaDU0KHURSTAgzRibyzrocjhU2cpczWN1IVz4L4QnwzmwoPe35IJVSbZ4mhQ7kfyb0ocLt5rWVB5q2Q3AUXPd3OHUI5t+r4wtKKU0KHUnvuFAuHdSV17860LQrkQB6jrUuU935gTXFtlKqU9Ok0MHcdUEfCkoqeGvNoabvNPZeGH4zLP2N3r+gVCenSaGDGdkrhpG9onnpy/1UuprYHSQCV86BlMvgg4dhkz6pTanOSpNCB3TnhD4cyi/h421Hm76TXwDc8Cokn2+NL+xY6LkAlVJtliaFDuiSQV3pGx/K7z/ZRWlFM+Y48g+Gm+dBjxHw71mw4Q2PxaiUaps0KXRATofwq+lDOHCimGebet9ClcAwuPVd6HUevP8dWPZ70MdaKNVpaFLooMb3i2PGyEReWL6P3bmFzds5KAJueRuG3Qhf/BoWPgAVTbj3QSnV7mlS6MB+NGUgIQFOfvPRjubv7BcA1/wNJvwvrH8NXpwEudtaP0ilVJuiSaEDiwkN4IGLUli66zjLdh9v/gFEYPLPrFbDmTx4YSKs/LM+i0GpDkyTQgd32/heJMeGcM/r63j9v1m06LHXKZfAd/4L/S6GT/8P/n4xZK9t9ViVUr6nSaGDC/RzMveusYzqHcNP39/Gu+tzWnag0Di46V9w3UtQkA1/nwxv3ACHN7RuwEopn9Kk0AkkRAbzyqxRpPeM4reLdlBQUtGyA4nA0OvhgfVw0U/h0CqrS+n1a2HXIu1WUqoD0KTQSTjsy1Tzz5Tz9Ge7z+1ggeFwwffhwS1w0U/g2HaYexM8mwZf/BaObtXLWJVqpzQpdCJDekRy46ie/GvVwaY9jKcxQRFwwQ+s5DDjVYjuBcuehL+eB3PS4JP/g4NfgauFLROllNdJiwYe24iMjAyzdq0OeDbHofxiJj21lFvH9uKxqwa3/gcUHYNdH8GOD2DfUnBXgH8oJI2CnuOhx0jonmaNUSilfEJE1hljMura5uftYJRvJcWEcE16D+auPsgd5/cmKSakdT8grAuMnGW9Sgtg7xI4sBIO/BeW/haw/wiJ6AGx/azWRXQyRPWC6N7WekisNX6hlPI6bSl0QgdPFDN1zgrCgvx4/Y4x9OsS5p0PLi2AI5vhyEbr/eR+OJkFZ2rdQ+EMgLCuVoKp/R4ab41pBIRBQKj9spf9gjSZKNUEDbUUNCl0UtsOFzDzH6sREd69d3zrtxiao6wITh20EsTJLCg6anVDFeV+/X4mj+pWRn3EWStZ1EgY/sFW0vALAGcg+Nmvmsu1152BVn2/ICtR+QXWWq5RX5ORakc0Kag67ckt5LrnVxIXHsg794wnOjTA1yHVz1UJxXlWq6L8DJQXWcmk/MzX6/UuF0F5MbjKoLLcfi+DylIwrfQIUmftZBPQjCRUlXhqLPsFfZ3I/IO/mZCq3wPP/gxNTqoJNCmoeq3en8+tL61iSPcI3vifsQQHOH0dkne5KmskibKvE0dlKbjKv04e1ctlddSvWrb3q048pbWSUK06laVnf15jLaGmcPjXSkZ1JaWarZ+gOtYbSmB11Q/45jaHnyaoNkwHmlW9RveO4dkb0/jOv9Zz1+treWrGcLpGBPk6LO9x+lmvgFDfxmEMuCtrJIwSa2bamu/VSaXW+1llpd9McLWTUmkBVB4/O3FVJ77Waj1JrQRSowXl9LPeHf7WssMfnP5WInEG2Mu1tjn9re5Bd4VVJzDCGlvyD6mxbx37nbUeUMfn+ddY72R/ENXDYy0FEUkCXgO6Yv0J9IIx5lkRiQHeBJKBLOAGY8xJERHgWWAKUAzMMsasb+gztKXQet5cc5Cfvr+NQKeD524dwYSUeF+HpHylduupZsI4q4VTT4uper2OhOOqsF/lVhJ0VVhf9K4Ke728xnLVtkrr3V1pfYG7ylqv2+8sYo1BBYZbL79AEMfXL4fTSkwOp5VQql+11/3A4bBirPp+dTgbTkZVxxXH2ctOfwiKsuI5q57TumovrGX/T33SfSQiCUCCMWa9iIQD64CrgVlAvjHmCRF5FIg2xjwiIlOA+7GSwhjgWWPMmIY+Q5NC68rKO8M9/1xH9skS3rl3PAO6hfs6JKW+yRioKIbS01YLqippfCOZVNSRdOpbtxNSRTGUnbaO7aqwv9jtl7vy63e3y36vuVxRY9n19Rd7VSuwZoKr+txzMfWPMOqOFu3aJsYUROR94M/2a6Ix5oidOJYaYwaIyN/s5bl2/V1V9eo7piaF1nf4VAlX/+VLyird3Dy6J7efl9y5upOU8hZjvk4ixg3GZa1XJyGXlTiK862LJdyus+vEp0JUUos+2udjCiKSDKQDq4CuNb7oj2J1LwH0AA7V2C3bLjsrKYjIXcBdAD179vRYzJ1V96hg3vifMfzh0928uGIfL3+5n5njk7nnwr7EtOWrk5Rqb0S+HtNqSGSid+KxeTwpiEgY8A7woDHmtNS4IsEYY0SkWU0VY8wLwAtgtRRaM1ZlSekazl+/PZJD+cU88/ke/r5iH/9adZCLB3bhvH5xXDciEYdDryxRqiPy6IR4IuKPlRDeMMa8axfn2t1GVeMOx+zyHKBmWyjRLlM+khQTwh9uGM4nD17AJYO6snLvCX7w9mZmvryaY4X6zGalOiKPtRTsq4leAnYYY/5YY9MCYCbwhP3+fo3y74rIPKyB5oKGxhOU96R0DefpG9MwxjBvzSF+vmAbk36/lBtH9SQ4wEGA00lCVBBXDe9OkL91Wd8n245yuqSCa9J74OfUyXiVai88efXR+cAKYAtQdf3Yj7HGFd4CegIHsC5JzbeTyJ+By7EuSb3dGNPgKLIONPvG/rwz/O7jnSzaehSHgNv+FeoRFcw9E/tS6XLzi4XbARjQNZzfXDuUET2jyCsqJy7MGpfIPFZEUkxIdRKpeey8ojISo4NJiAxm19FC/rXqAA9d0p+oEB3TUKo1tImrjzxBk4JvVbrcOB1Chcuw9kA+v/1oJ1tyCgC4sH88149M5IlFOzlSUEL3qGCyT5bQr0sYoYF+bDp0iugQfy4b3I3IYH8u6B9P9slifvTuFtwG/BzC764fxpzFe8g6UUxqt3Bemz2aLjWuhCopd511B/ZX+05w8kw5lw/phujdtErVS5OC8gpjDLtzi9h46CTT03oQ5O+kqKySP3y6i0P5xaQlRfHZ9lwKyyq5aVQS6w6cZPX+fM6UuSh3WY3JCSlx3DmhD09/vpsNB0/hEPjfSwfwpyV7cBuYMqQbN4xKYtGWo/xz1QHrstnxySzfk8fjH27HbeDigV1J7xlFYnQwU4cm8PmOXJbtPk6A08HFg7pyfr+4OpOG223ILy4n93QpxwrLOH66jAHdwhmeFNXgv/lQfgn78ooYlRxDaODXPbJllS4+2nKEjF4xvp1wUKlaNCmoNq20wsXCTYc5fKqUeyf2JcDPQUFJBf/71kYu6B/PbeOSyTxWxOv/zeLdDTkUllYCVgL5MjOvuvvq4oFdGNkrhmc+301ZpZVkokP8OVlcQWSwP5UuN2fKXfSJDyU6JIBAPweBfg78nQ4OnSwh81ghFa5v/n+YOiyBwd0jiAjyx+kQVu/PJ6+ojMhgf9ZmneToaWvQPbVbOH/79kiiggOYvzGHF5bvI+dUCQmRQTxx3TBe+s9+hidG8r3JKXy59wROEXrHh/LqyiySYkL49theAOw8eponF+3kqrTujEqOYXN2AeenxBER5A9YiUhbQupcaFJQHUZJuYtPtx+le1Qwo5Jj2HHkNLtzC4kJDWB83zicDqG80o3bGJbuOs68NQeZkBLPzHG9cBnDW2uzWbbrGKUVbkorXJRVuimrdNEtMpiBCeF0jwymS3ggXSKCiAkN4O11h3j5yyyKy13VMcSGBpAYHcyJM+UM7RHJef3iCA108rP52ygsq6yul94ziptGJfH4hzs4XVpJsL+TkgoXMaEB5J8p/8a/7e4L+9A3Loxff7id4nIXle6v/28mx4bw/csGcPhUCfPWHKKk3MWzN6UzoGs4Ww8XsO94EflnKnAIDEmMpKzCxc6jhezJLcLfKcSEBrI5+xQuY0jtFs6Vw7oztk9sky8tNsbgNuA8h0uRjTEYQ/VnanLzHU0KSp0DYwxllW5Ol1RQUuEiKTqkzi/T/Xln+Hx7LhVuN+P6xJLeMxqALdkFLNx8mLsu6MNn23OZt/og3x6XTESQHzuPFnLl8O4890Um/16XDUCf+FBevX00Gw+d4mhBKUkxwfzs/W0cKywDIC0pioKSCg7mF+O2v2jrIgI9Y0KoqHRzvKiMIT0iCfJzsjWngMKySuLCAhmVHE1Gcgyp3cJxOoSlu46z8+hpikoryTlVgsttGJ4Uxc6jp8krLOfq9O5EhQSQX1ROl4hAukUGEeB0sDm7gEMni8krKiOvsJwgfwe940IZnhRFarcIKlxu/rwkExF45fbR/PKDbezOLeLV2aPxdwqnSyro16X+aVVOnilnS04B2w6fJtjfwcheMQzpEYGIUFrhIsjfidtt+O++E2zNKaBnTAhXDE2o93iniss5fKqUQd0jzvr5lVe66Rsf6pMr5j7bnktYoB/j+sZ6/LM0KSjVxrndhq2HCwjyd5IcG0qA39lfSgUlFdYVW9HBdIkIoqCkgr98kUlIgJOMXjGkdA0jNjSA0ko3W3MKCPZ3ktI1jJAAa4yj5l/lpRUuFm09wvLdeazJyif7ZEn15zgdwsCEcMID/UmICsLtNmw4dIq+8WFEhfjz4eYjuI0hMjiA/DNl1V13YYF+9I4LJS4sgNiwQEoqXGTmFrH7WGF10uoVG0Ku3dVWWuEm2N9JaKAfhaUVlFW6mTosgUEJERSXVxIW6E9EsB/5ReW8v+kwmceKvnHOxvaJwSHCyr0nmJASx8nicrbmnK7eftu4Xnz/sgHV3W5gJYN31+fw7OI9FJZW8LdvZ3DxwC78ddk+fv/JTtwGYkIDeOHbIzlWWMbflu3l4UsHcGH/b048tzWngKW7jnGquILRvWOYOKDLN35uTZV5rIgrnl1OoJ+Txf97IV0jgsjKO8M/vzpARnI0Fw/s2qqJSpOCUqpeRwpKyMorprTCRVpSVIMPWyqtcOHnEPycDipdVgvkTJmL3nGhdXYtFZZWcOBEMYWllWQkR7NqXz4PvrmB+y9KYUTPaL47dz2jkmPoFhHECyv2UV7pPusyZ7Cmd78otQvDekQyuEckxeWVfLz1KH/5Yi9+DuHSwV35eOtR/J0OHr6kPxMHxPO35ft4Yfk+/J1C77hQKl1Wa+9YYSkVLsO4PrGcKa9kd24h8eGBHMovYeqwBCanduHPSzLJOVVCucuNv9NBeaWbCSlxdIsIIj48kC7hgeSfKecvS/fichsCnA7KXW66Rwbxk2mDKK90s+PIaYrKKvF3OogLCyAtKRqXMRzML+ZQfjEHTxRzML+Y7JPFDE+KoqTcxa7cQsoq3VyQEsewxCieX7qXkgqr2zIqxJ9xfWKJCQ2gV2wIN43ueVayay5NCkqpNqO+sYSSchciEOjnoKTCRWFpJQ4R4sMD6z1O1RhFXcdcf/Akn2w7yv7jZwjwcxDg56BrRBBThiQwpEcEeUXlzH5lDVEh/szISOLKYQmICMcLy7jr9bUkRYfwy+mD+dOSTFbtP8HxwjJOFJVXj/VMGdqN31wzlNBAP5bvPs7vPt7FrtxCAAL8HIQF+lHhcldfGFElwM9BUnQwvWJD6RoRyIebj3C6tJJfTh9MQXEFf/hsN2Bd1v34NUPYcaSQT7Ydta/Uq+TEmXLCg/z49dVDmJ7Wo0U/A00KSinVCtxuw8nicorKKukZE3JWIqpwufl0Wy49ooMZ1iOyetypoKSCzdmnCPRz0jMmhC7hgWeNSeUVlbFy7wmmDk3AGMPinccYlhhJQmRwnTFszSngL19kcveFfUlr4HLphmhSUEopVa2hpKCT0iillKqmSUEppVQ1TQpKKaWqaVJQSilVTZOCUkqpapoUlFJKVdOkoJRSqpomBaWUUtXa9c1rInIc65GeLREH5LViOK2prcamcTWPxtV8bTW2jhZXL2PMN2f5o50nhXMhImvru6PP19pqbBpX82hczddWY+tMcWn3kVJKqWqaFJRSSlXrzEnhBV8H0IC2GpvG1TwaV/O11dg6TVyddkxBKaXUN3XmloJSSqlaNCkopZSq1imTgohcLiK7RCRTRB71YRxJIvKFiGwXkW0i8j27/DERyRGRjfZrig9iyxKRLfbnr7XLYkTkMxHZY79HezmmATXOyUYROS0iD/rqfInIP0TkmIhsrVFW5zkSyxz7d26ziIzwcly/F5Gd9me/JyJRdnmyiJTUOHd/9XJc9f7sRORH9vnaJSKXeSquBmJ7s0ZcWSKy0S73yjlr4PvBs79j1nNOO88LcAJ7gT5AALAJGOSjWBKAEfZyOLAbGAQ8Bnzfx+cpC4irVfY74FF7+VHgSR//HI8CvXx1voALgBHA1sbOETAFWAQIMBZY5eW4LgX87OUna8SVXLOeD85XnT87+//BJiAQ6G3/n3V6M7Za2/8A/Myb56yB7weP/o51xpbCaCDTGLPPGFMOzAOm+yIQY8wRY8x6e7kQ2AG07Enc3jEdeNVefhW42oexTAb2GmNaekf7OTPGLAfyaxXXd46mA68Zy1dAlIgkeCsuY8ynxpiqJ8h/BSR64rObG1cDpgPzjDFlxpj9QCbW/12vxybWg5hvAOZ66vPriam+7weP/o51xqTQAzhUYz2bNvBFLCLJQDqwyi76rt0E/Ie3u2lsBvhURNaJyF12WVdjzBF7+SjQ1QdxVbmJs/+T+vp8VanvHLWl37vZWH9RVuktIhtEZJmITPBBPHX97NrS+ZoA5Bpj9tQo8+o5q/X94NHfsc6YFNocEQkD3gEeNMacBp4H+gJpwBGspqu3nW+MGQFcAdwnIhfU3Gis9qpPrmcWkQDgKuDfdlFbOF/f4MtzVB8R+T+gEnjDLjoC9DTGpAMPA/8SkQgvhtQmf3a13MzZf4B49ZzV8f1QzRO/Y50xKeQASTXWE+0ynxARf6wf+BvGmHcBjDG5xhiXMcYNvIgHm831Mcbk2O/HgPfsGHKrmqP2+zFvx2W7AlhvjMm1Y/T5+aqhvnPk8987EZkFTANusb9MsLtnTtjL67D67vt7K6YGfnY+P18AIuIHXAu8WVXmzXNW1/cDHv4d64xJYQ2QIiK97b84bwIW+CIQu6/yJWCHMeaPNcpr9gNeA2ytva+H4woVkfCqZaxByq1Y52mmXW0m8L4346rhrL/cfH2+aqnvHC0AbrOvEBkLFNToAvA4Ebkc+CFwlTGmuEZ5vIg47eU+QAqwz4tx1fezWwDcJCKBItLbjmu1t+Kq4WJgpzEmu6rAW+esvu8HPP075ukR9Lb4whql342V4f/Ph3Gcj9X02wxstF9TgNeBLXb5AiDBy3H1wbryYxOwreocAbHAYmAP8DkQ44NzFgqcACJrlPnkfGElpiNABVb/7R31nSOsK0L+Yv/ObQEyvBxXJlZ/c9Xv2V/tutfZP+ONwHrgSi/HVe/PDvg/+3ztAq7w9s/SLn8FuKdWXa+cswa+Hzz6O6bTXCillKrWGbuPlFJK1UOTglJKqWqaFJRSSlXTpKCUUqqaJgWllFLVNCmoTkVEfisik0TkahH5UTP3jReRVfb0Bl6dDkJEirz5earz0qSgOpsxWBPCXQgsb+a+k4Etxph0Y8yKVo9MqTZAk4LqFMR6nsBmYBTwX+B/gOdF5Gd11E0WkSX2JG2LRaSniKRhTVk83Z5DP7jWPiPtydHWicgnNaYhWCoiz9r7bBWR0XZ5jIjMtz/jKxEZZpeHicjLYj3LYrOIXFfjMx4XkU12/a522Qz7uJtEpLlJTqlv8uRdgvrSV1t6YSWEPwH+wJcN1FsIzLSXZwPz7eVZwJ/rqO8PrATi7fUbgX/Yy0uBF+3lC7Dn4bfj+Lm9fBGw0V5+EnimxrGj7XeDfecsVnL6ib28BehhL0f5+hzrq/2//Fo5xyjVlo3AmrojFWtu+vqMw5oEDaxpGH7XyHEHAEOAz6zpanBiTZlQZS5Yc/aLSIRYTz07H2u6BIwxS0Qk1p5p82Ks+biwt520F8uBD+zldcAl9vKXwCsi8hZQNWGaUi2mSUF1eHbXzytYs0bmASFWsWwExhljSs71I4Btxphx9WyvPZdMS+aWqTDGVO3nwv6/a4y5R0TGAFOBdSIy0tgzeCrVEjqmoDo8Y8xGY0waXz/OcAlwmTEmrZ6EsJKv/1q/BWhsUHkXEC8i48Ca7lhEBtfYfqNdfj7WzJUF9jFvscsnAnnGmiv/M+C+qh2lkQcGiUhfY8wqY8zPgOOcPXWyUs2mLQXVKYhIPHDSGOMWkVRjzPYGqt8PvCwiP8D6or29oWMbY8pF5HpgjohEYv2/egZrJk2AUhHZgDX2MNsuewz4hz34XczXUyH/GviLWA+QdwG/oOFuod+LSApWa2UxVveYUi2ms6Qq5UEishTrwfRrfR2LUk2h3UdKKaWqaUtBKaVUNW0pKKWUqqZJQSmlVDVNCkoppappUlBKKVVNk4JSSqlq/w81nnfyXIGiKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhWKmlGwCRd_",
        "colab_type": "code",
        "outputId": "b000e460-30f2-47b4-ab16-5b1bdd0b9daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "mean_squared_error(y_train, y_pred_train), mean_squared_error(y_test, y_pred_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22.77423909605731, 18.165510493496424)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4a9b6f9e-cd52-481c-a93d-08063c25ab19"
      },
      "source": [
        "##### Your Code Here #####\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdORyEbDCReF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t6wUUfiCReJ",
        "colab_type": "code",
        "outputId": "910f4b95-8e13-4c9f-f884-0dfef21cb974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_train[0].shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppk1GlbXCReM",
        "colab_type": "code",
        "outputId": "68ea2985-9190-417a-89e4-d06102547b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28,28)),\n",
        "    Dense(784, activation=\"relu\"),\n",
        "    Dense(784, activation=\"relu\"),\n",
        "    Dense(784, activation=\"relu\"),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x=X_train, \n",
        "        y=y_train, \n",
        "        epochs=15, \n",
        "        validation_data=(X_test, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 1.6254 - accuracy: 0.7897 - val_loss: 0.4789 - val_accuracy: 0.8295\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4458 - accuracy: 0.8402 - val_loss: 0.5081 - val_accuracy: 0.8156\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4118 - accuracy: 0.8545 - val_loss: 0.4612 - val_accuracy: 0.8419\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3994 - accuracy: 0.8582 - val_loss: 0.4170 - val_accuracy: 0.8541\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3855 - accuracy: 0.8643 - val_loss: 0.4459 - val_accuracy: 0.8517\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3653 - accuracy: 0.8686 - val_loss: 0.4013 - val_accuracy: 0.8643\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.3522 - accuracy: 0.8769 - val_loss: 0.4564 - val_accuracy: 0.8459\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3443 - accuracy: 0.8789 - val_loss: 0.4165 - val_accuracy: 0.8571\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3358 - accuracy: 0.8808 - val_loss: 0.3921 - val_accuracy: 0.8616\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3261 - accuracy: 0.8847 - val_loss: 0.4632 - val_accuracy: 0.8572\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.3180 - accuracy: 0.8858 - val_loss: 0.4058 - val_accuracy: 0.8607\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.3087 - accuracy: 0.8896 - val_loss: 0.4049 - val_accuracy: 0.8670\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3127 - accuracy: 0.8875 - val_loss: 0.3937 - val_accuracy: 0.8654\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3092 - accuracy: 0.8911 - val_loss: 0.4329 - val_accuracy: 0.8616\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.2998 - accuracy: 0.8935 - val_loss: 0.3934 - val_accuracy: 0.8713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f13a86ac400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnjUnGAqCReP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist1 = model.history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYleA0CDCReR",
        "colab_type": "code",
        "outputId": "0414dbbb-d9d5-4f3b-d107-852b7cb0107d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.plot(hist1['loss'], label='Training Loss')\n",
        "plt.plot(hist1['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend();"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}